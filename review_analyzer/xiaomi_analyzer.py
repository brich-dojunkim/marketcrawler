# batch_xiaomi_review_analyzer.py
"""
ìƒ¤ì˜¤ë¯¸ ìƒí’ˆ ë¦¬ë·° ì¼ê´„ ë¶„ì„ê¸°
ê°œë³„ ë¦¬ë·° íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ ìƒí’ˆ ì •ë³´ì™€ í•¨ê»˜ í†µí•© ê²°ê³¼í‘œ ìƒì„±
"""

import os
import sys
import pandas as pd
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import warnings
from datetime import datetime

warnings.filterwarnings('ignore')

# review_analyzer ëª¨ë“ˆ import
sys.path.append('/Users/brich/Desktop/marketcrawler/review_analyzer')
from utils.data_loader import load_csv_data, identify_columns, validate_data
from core.analyzer import MorphologicalAnalyzer
from core.sentiment import SentimentAnalyzer
from keywords.extractor import KeywordExtractor

class BatchXiaomiReviewAnalyzer:
    """ìƒ¤ì˜¤ë¯¸ ìƒí’ˆ ë¦¬ë·° ì¼ê´„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, reviews_dir: str, product_info_path: str, output_dir: str):
        """
        Args:
            reviews_dir: ê°œë³„ ë¦¬ë·° CSV íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
            product_info_path: ìƒí’ˆ ì •ë³´ CSV íŒŒì¼ ê²½ë¡œ
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.reviews_dir = Path(reviews_dir)
        self.product_info_path = product_info_path
        self.output_dir = Path(output_dir)
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.morphological_analyzer = MorphologicalAnalyzer()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.keyword_extractor = KeywordExtractor()
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.product_info_df = None
        self.analysis_results = []
        
        print("ğŸš€ ìƒ¤ì˜¤ë¯¸ ìƒí’ˆ ë¦¬ë·° ì¼ê´„ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def load_product_info(self) -> bool:
        """ìƒí’ˆ ì •ë³´ CSV ë¡œë“œ"""
        try:
            self.product_info_df = pd.read_csv(self.product_info_path)
            print(f"âœ… ìƒí’ˆ ì •ë³´ ë¡œë“œ ì™„ë£Œ: {len(self.product_info_df)}ê°œ ìƒí’ˆ")
            print(f"ğŸ“Š ìƒí’ˆ ì •ë³´ ì»¬ëŸ¼: {list(self.product_info_df.columns)}")
            return True
        except Exception as e:
            print(f"âŒ ìƒí’ˆ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def extract_product_name_from_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ"""
        # reviews_{product_name}_{timestamp}.csv í˜•íƒœì—ì„œ product_name ì¶”ì¶œ
        pattern = r'reviews_(.+?)_\d{8}_\d{6}\.csv'
        match = re.match(pattern, filename)
        if match:
            product_name = match.group(1).replace('_', ' ').replace('-', ' ')
            return product_name
        return filename.replace('.csv', '')
    
    def find_matching_product_info(self, extracted_name: str) -> Optional[Dict]:
        """ì¶”ì¶œëœ ìƒí’ˆëª…ìœ¼ë¡œ ìƒí’ˆ ì •ë³´ ë§¤ì¹­"""
        if self.product_info_df is None:
            return None
        
        # 1. ì •í™•í•œ ë§¤ì¹­ ì‹œë„
        for idx, row in self.product_info_df.iterrows():
            product_name = str(row['name']).lower()
            if extracted_name.lower() in product_name or product_name in extracted_name.lower():
                return {
                    'category': row['category'],
                    'subcategory': row['subcategory'],
                    'full_name': row['name'],
                    'sale_price': row.get('sale_price', 0),
                    'rating': row.get('rating', 0),
                    'rating_count': row.get('rating_count', 0)
                }
        
        # 2. ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (í‚¤ì›Œë“œ ê¸°ë°˜)
        extracted_keywords = extracted_name.lower().split()
        best_match = None
        max_matches = 0
        
        for idx, row in self.product_info_df.iterrows():
            product_name = str(row['name']).lower()
            matches = sum(1 for keyword in extracted_keywords if keyword in product_name)
            if matches > max_matches and matches >= 2:  # ìµœì†Œ 2ê°œ í‚¤ì›Œë“œ ë§¤ì¹­
                max_matches = matches
                best_match = {
                    'category': row['category'],
                    'subcategory': row['subcategory'],
                    'full_name': row['name'],
                    'sale_price': row.get('sale_price', 0),
                    'rating': row.get('rating', 0),
                    'rating_count': row.get('rating_count', 0)
                }
        
        return best_match
    
    def analyze_single_review_file(self, file_path: Path) -> Optional[Dict]:
        """ê°œë³„ ë¦¬ë·° íŒŒì¼ ë¶„ì„"""
        try:
            print(f"\nğŸ“ ë¶„ì„ ì¤‘: {file_path.name}")
            
            # 1. ë°ì´í„° ë¡œë“œ
            df = load_csv_data(str(file_path))
            if df is None or len(df) == 0:
                print(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {file_path.name}")
                return None
            
            # 2. ì»¬ëŸ¼ ì‹ë³„
            text_columns, rating_columns = identify_columns(df)
            if not text_columns:
                print(f"âš ï¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì—†ìŒ: {file_path.name}")
                return None
            
            text_col = text_columns[0]
            rating_col = rating_columns[0] if rating_columns else None
            
            # 3. ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            if not validate_data(df, text_col, rating_col):
                return None
            
            # 4. ê¸°ë³¸ í†µê³„
            total_reviews = len(df)
            avg_review_length = df[text_col].str.len().mean()
            avg_rating = df[rating_col].mean() if rating_col else None
            
            # 5. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ê°„ë‹¨íˆ)
            df['cleaned_review'] = df[text_col].fillna('')
            df = df[df['cleaned_review'].str.len() > 0]  # ë¹ˆ ë¦¬ë·° ì œê±°
            
            if len(df) == 0:
                return None
            
            # 6. í˜•íƒœì†Œ ë¶„ì„
            df = self.morphological_analyzer.tokenize_dataframe(df, text_col)
            
            # 7. ê°ì„± ë¶„ì„
            if rating_col:
                df = self.sentiment_analyzer.create_sentiment_labels(
                    df, method='rating', rating_column=rating_col
                )
            else:
                df['sentiment'] = 'neutral'
            
            # 8. í‚¤ì›Œë“œ ì¶”ì¶œ
            texts = df['tokens_str'].tolist()
            self.keyword_extractor.extract_auto_stopwords(texts)
            
            # TF-IDF í‚¤ì›Œë“œ
            tfidf_keywords = self.keyword_extractor.extract_keywords_tfidf(df)
            top_keywords = [word for word, score in tfidf_keywords[:10]]
            
            # ê°ì„±ë³„ í‚¤ì›Œë“œ
            sentiment_keywords = self.keyword_extractor.extract_sentiment_keywords(df)
            
            # 9. ê°ì„± ë¶„í¬ ê³„ì‚°
            sentiment_counts = df['sentiment'].value_counts()
            total_sentiment = len(df)
            
            positive_ratio = sentiment_counts.get('positive', 0) / total_sentiment * 100
            negative_ratio = sentiment_counts.get('negative', 0) / total_sentiment * 100
            neutral_ratio = sentiment_counts.get('neutral', 0) / total_sentiment * 100
            
            # 10. ìƒí’ˆ ì •ë³´ ë§¤ì¹­
            extracted_name = self.extract_product_name_from_filename(file_path.name)
            product_info = self.find_matching_product_info(extracted_name)
            
            # 11. ê²°ê³¼ êµ¬ì„±
            result = {
                'file_name': file_path.name,
                'extracted_name': extracted_name,
                'category': product_info['category'] if product_info else 'ë¯¸ë¶„ë¥˜',
                'subcategory': product_info['subcategory'] if product_info else 'ë¯¸ë¶„ë¥˜',
                'full_product_name': product_info['full_name'] if product_info else extracted_name,
                'sale_price': product_info['sale_price'] if product_info else 0,
                'store_rating': product_info['rating'] if product_info else 0,
                'store_rating_count': product_info['rating_count'] if product_info else 0,
                'total_reviews': total_reviews,
                'valid_reviews': len(df),
                'avg_review_length': round(avg_review_length, 1),
                'avg_rating': round(avg_rating, 2) if avg_rating else None,
                'positive_count': sentiment_counts.get('positive', 0),
                'negative_count': sentiment_counts.get('negative', 0),
                'neutral_count': sentiment_counts.get('neutral', 0),
                'positive_ratio': round(positive_ratio, 1),
                'negative_ratio': round(negative_ratio, 1),
                'neutral_ratio': round(neutral_ratio, 1),
                'top_keywords': ', '.join(top_keywords[:5]),
                'positive_keywords': ', '.join([word for word, score in sentiment_keywords.get('positive', [])[:3]]),
                'negative_keywords': ', '.join([word for word, score in sentiment_keywords.get('negative', [])[:3]]),
                'all_keywords': ', '.join(top_keywords)
            }
            
            print(f"âœ… ë¶„ì„ ì™„ë£Œ: {extracted_name} ({len(df)}ê°œ ë¦¬ë·°)")
            return result
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨ {file_path.name}: {e}")
            return None
    
    def run_batch_analysis(self) -> List[Dict]:
        """ì¼ê´„ ë¶„ì„ ì‹¤í–‰"""
        print("\n" + "="*60)
        print("ğŸ”„ ìƒ¤ì˜¤ë¯¸ ìƒí’ˆ ë¦¬ë·° ì¼ê´„ ë¶„ì„ ì‹œì‘")
        print("="*60)
        
        # 1. ìƒí’ˆ ì •ë³´ ë¡œë“œ
        if not self.load_product_info():
            return []
        
        # 2. ë¦¬ë·° íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        review_files = list(self.reviews_dir.glob("*.csv"))
        print(f"ğŸ“ ë°œê²¬ëœ ë¦¬ë·° íŒŒì¼: {len(review_files)}ê°œ")
        
        if not review_files:
            print("âŒ ë¦¬ë·° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # 3. ê° íŒŒì¼ ë¶„ì„
        self.analysis_results = []
        for i, file_path in enumerate(review_files, 1):
            print(f"\n[{i}/{len(review_files)}] ì²˜ë¦¬ ì¤‘...")
            result = self.analyze_single_review_file(file_path)
            if result:
                self.analysis_results.append(result)
        
        print(f"\nâœ… ì¼ê´„ ë¶„ì„ ì™„ë£Œ: {len(self.analysis_results)}ê°œ ìƒí’ˆ")
        return self.analysis_results
    
    def create_comprehensive_report(self) -> str:
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.analysis_results:
            print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"xiaomi_batch_analysis_{timestamp}.xlsx"
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            
            # 1. ë©”ì¸ ìš”ì•½ í…Œì´ë¸”
            self._create_main_summary_sheet(writer)
            
            # 2. ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
            self._create_category_analysis_sheet(writer)
            
            # 3. ìƒì„¸ ë¶„ì„ ê²°ê³¼
            self._create_detailed_analysis_sheet(writer)
            
            # 4. í‚¤ì›Œë“œ ë¶„ì„
            self._create_keyword_analysis_sheet(writer)
            
            # 5. í†µê³„ ìš”ì•½
            self._create_statistics_summary_sheet(writer)
        
        print(f"\nğŸ‰ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“„ íŒŒì¼ ê²½ë¡œ: {output_file}")
        
        return str(output_file)
    
    def _create_main_summary_sheet(self, writer):
        """ë©”ì¸ ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        df_results = pd.DataFrame(self.analysis_results)
        
        # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
        summary_columns = [
            'full_product_name', 'category', 'subcategory', 'total_reviews', 
            'avg_rating', 'positive_ratio', 'negative_ratio', 'neutral_ratio',
            'top_keywords', 'positive_keywords', 'negative_keywords', 'sale_price'
        ]
        
        summary_df = df_results[summary_columns].copy()
        summary_df.columns = [
            'ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ì„œë¸Œì¹´í…Œê³ ë¦¬', 'ì´ ë¦¬ë·°ìˆ˜', 'í‰ê· í‰ì ', 
            'ê¸ì •ë¹„ìœ¨(%)', 'ë¶€ì •ë¹„ìœ¨(%)', 'ì¤‘ë¦½ë¹„ìœ¨(%)', 'ì£¼ìš”í‚¤ì›Œë“œ', 
            'ê¸ì •í‚¤ì›Œë“œ', 'ë¶€ì •í‚¤ì›Œë“œ', 'íŒë§¤ê°€ê²©'
        ]
        
        # ì •ë ¬ (ì¹´í…Œê³ ë¦¬ -> ê¸ì •ë¹„ìœ¨ ìˆœ)
        summary_df = summary_df.sort_values(['ì¹´í…Œê³ ë¦¬', 'ê¸ì •ë¹„ìœ¨(%)'], ascending=[True, False])
        
        summary_df.to_excel(writer, sheet_name='1_ì „ì²´ìš”ì•½', index=False)
        print("âœ… ë©”ì¸ ìš”ì•½ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def _create_category_analysis_sheet(self, writer):
        """ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        df_results = pd.DataFrame(self.analysis_results)
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_stats = df_results.groupby('category').agg({
            'total_reviews': 'sum',
            'avg_rating': 'mean',
            'positive_ratio': 'mean',
            'negative_ratio': 'mean',
            'neutral_ratio': 'mean',
            'sale_price': 'mean',
            'full_product_name': 'count'
        }).round(2)
        
        category_stats.columns = [
            'ì´ ë¦¬ë·°ìˆ˜', 'í‰ê· í‰ì ', 'í‰ê·  ê¸ì •ë¹„ìœ¨', 'í‰ê·  ë¶€ì •ë¹„ìœ¨', 
            'í‰ê·  ì¤‘ë¦½ë¹„ìœ¨', 'í‰ê·  íŒë§¤ê°€ê²©', 'ìƒí’ˆìˆ˜'
        ]
        
        category_stats = category_stats.sort_values('í‰ê·  ê¸ì •ë¹„ìœ¨', ascending=False)
        category_stats.to_excel(writer, sheet_name='2_ì¹´í…Œê³ ë¦¬ë³„ë¶„ì„')
        print("âœ… ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def _create_detailed_analysis_sheet(self, writer):
        """ìƒì„¸ ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        df_results = pd.DataFrame(self.analysis_results)
        
        detailed_columns = [
            'full_product_name', 'category', 'subcategory', 'total_reviews', 
            'valid_reviews', 'avg_review_length', 'avg_rating', 'store_rating',
            'positive_count', 'negative_count', 'neutral_count', 
            'positive_ratio', 'negative_ratio', 'neutral_ratio',
            'sale_price', 'all_keywords'
        ]
        
        detailed_df = df_results[detailed_columns].copy()
        detailed_df.columns = [
            'ìƒí’ˆëª…', 'ì¹´í…Œê³ ë¦¬', 'ì„œë¸Œì¹´í…Œê³ ë¦¬', 'ì´ ë¦¬ë·°ìˆ˜', 'ìœ íš¨ ë¦¬ë·°ìˆ˜',
            'í‰ê·  ë¦¬ë·°ê¸¸ì´', 'ë¦¬ë·° í‰ê· í‰ì ', 'ìŠ¤í† ì–´ í‰ì ', 'ê¸ì •ìˆ˜', 'ë¶€ì •ìˆ˜', 
            'ì¤‘ë¦½ìˆ˜', 'ê¸ì •ë¹„ìœ¨', 'ë¶€ì •ë¹„ìœ¨', 'ì¤‘ë¦½ë¹„ìœ¨', 'íŒë§¤ê°€ê²©', 'ì „ì²´í‚¤ì›Œë“œ'
        ]
        
        detailed_df.to_excel(writer, sheet_name='3_ìƒì„¸ë¶„ì„', index=False)
        print("âœ… ìƒì„¸ ë¶„ì„ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def _create_keyword_analysis_sheet(self, writer):
        """í‚¤ì›Œë“œ ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        df_results = pd.DataFrame(self.analysis_results)
        
        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ë¶„ì„
        keyword_data = []
        
        for category in df_results['category'].unique():
            category_data = df_results[df_results['category'] == category]
            
            # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ìˆ˜ì§‘
            all_positive = ' '.join(category_data['positive_keywords'].fillna(''))
            all_negative = ' '.join(category_data['negative_keywords'].fillna(''))
            
            keyword_data.append({
                'ì¹´í…Œê³ ë¦¬': category,
                'ìƒí’ˆìˆ˜': len(category_data),
                'í‰ê·  ê¸ì •ë¹„ìœ¨': category_data['positive_ratio'].mean(),
                'ì£¼ìš” ê¸ì •í‚¤ì›Œë“œ': all_positive[:100],
                'ì£¼ìš” ë¶€ì •í‚¤ì›Œë“œ': all_negative[:100]
            })
        
        keyword_df = pd.DataFrame(keyword_data)
        keyword_df.to_excel(writer, sheet_name='4_í‚¤ì›Œë“œë¶„ì„', index=False)
        print("âœ… í‚¤ì›Œë“œ ë¶„ì„ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def _create_statistics_summary_sheet(self, writer):
        """í†µê³„ ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        df_results = pd.DataFrame(self.analysis_results)
        
        stats_data = [
            ['ì „ì²´ í†µê³„', '', ''],
            ['ë¶„ì„ëœ ìƒí’ˆ ìˆ˜', len(df_results), 'ê°œ'],
            ['ì´ ë¦¬ë·° ìˆ˜', df_results['total_reviews'].sum(), 'ê°œ'],
            ['í‰ê·  ë¦¬ë·° ìˆ˜ (ìƒí’ˆë‹¹)', df_results['total_reviews'].mean(), 'ê°œ'],
            ['ì „ì²´ í‰ê·  ê¸ì •ë¹„ìœ¨', df_results['positive_ratio'].mean(), '%'],
            ['ì „ì²´ í‰ê·  ë¶€ì •ë¹„ìœ¨', df_results['negative_ratio'].mean(), '%'],
            ['', '', ''],
            ['ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ìˆ˜', '', ''],
        ]
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìƒí’ˆ ìˆ˜
        category_counts = df_results['category'].value_counts()
        for category, count in category_counts.items():
            stats_data.append([category, count, 'ê°œ'])
        
        stats_df = pd.DataFrame(stats_data, columns=['í•­ëª©', 'ê°’', 'ë‹¨ìœ„'])
        stats_df.to_excel(writer, sheet_name='5_í†µê³„ìš”ì•½', index=False)
        print("âœ… í†µê³„ ìš”ì•½ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def print_summary(self):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.analysis_results:
            return
        
        df_results = pd.DataFrame(self.analysis_results)
        
        print("\n" + "="*60)
        print("ğŸ“Š ìƒ¤ì˜¤ë¯¸ ìƒí’ˆ ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        print(f"ğŸ”¢ ë¶„ì„ëœ ìƒí’ˆ ìˆ˜: {len(df_results)}ê°œ")
        print(f"ğŸ“ ì´ ë¦¬ë·° ìˆ˜: {df_results['total_reviews'].sum():,}ê°œ")
        print(f"â­ ì „ì²´ í‰ê·  ê¸ì •ë¹„ìœ¨: {df_results['positive_ratio'].mean():.1f}%")
        
        print(f"\nğŸ“‹ ì¹´í…Œê³ ë¦¬ë³„ í˜„í™©:")
        category_summary = df_results.groupby('category').agg({
            'full_product_name': 'count',
            'total_reviews': 'sum',
            'positive_ratio': 'mean'
        }).round(1)
        
        for category, row in category_summary.iterrows():
            print(f"   {category}: {row['full_product_name']}ê°œ ìƒí’ˆ, "
                  f"{row['total_reviews']:,}ê°œ ë¦¬ë·°, ê¸ì •ë¹„ìœ¨ {row['positive_ratio']}%")
        
        print(f"\nğŸ† ê¸ì •ë¹„ìœ¨ TOP 5 ìƒí’ˆ:")
        top_products = df_results.nlargest(5, 'positive_ratio')
        for idx, row in top_products.iterrows():
            print(f"   {row['full_product_name'][:30]:30} "
                  f"({row['category']:10}) ê¸ì •ë¹„ìœ¨: {row['positive_ratio']}%")
        
        print("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ê²½ë¡œ ì„¤ì •
    reviews_dir = "/Users/brich/Desktop/marketcrawler/crawler/output/reviews_unique"
    product_info_path = "/Users/brich/Desktop/marketcrawler/crawler/output/xiaomi_store_20250704_103745.csv"
    output_dir = "/Users/brich/Desktop/marketcrawler/output"
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    analyzer = BatchXiaomiReviewAnalyzer(reviews_dir, product_info_path, output_dir)
    
    # ì¼ê´„ ë¶„ì„ ì‹¤í–‰
    results = analyzer.run_batch_analysis()
    
    if results:
        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        output_file = analyzer.create_comprehensive_report()
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        analyzer.print_summary()
        
        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {output_file}")
    else:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()