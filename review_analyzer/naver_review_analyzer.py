# naver_review_analyzer.py
"""
ë„¤ì´ë²„ ìƒí’ˆ ë¦¬ë·° ì¼ê´„ ë¶„ì„ê¸°
ê°œë³„ ë¦¬ë·° íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ ìƒí’ˆ ì •ë³´ì™€ í•¨ê»˜ í†µí•© ê²°ê³¼í‘œ ìƒì„±
"""

import os
import sys
import pandas as pd
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import warnings
from datetime import datetime

warnings.filterwarnings('ignore')

# review_analyzer ëª¨ë“ˆ import
sys.path.append('/Users/brich/Desktop/marketcrawler/review_analyzer')
from utils.data_loader import load_csv_data, validate_data
from core.analyzer import MorphologicalAnalyzer
from core.sentiment import SentimentAnalyzer
from keywords.extractor import KeywordExtractor

class NaverReviewAnalyzer:
    """ë„¤ì´ë²„ ìƒí’ˆ ë¦¬ë·° ì¼ê´„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, reviews_dir: str, output_dir: str):
        """
        Args:
            reviews_dir: ê°œë³„ ë¦¬ë·° CSV íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.reviews_dir = Path(reviews_dir)
        self.output_dir = Path(output_dir)
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.morphological_analyzer = MorphologicalAnalyzer()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.keyword_extractor = KeywordExtractor()
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.analysis_results = []
        
        print("ğŸš€ ë„¤ì´ë²„ ìƒí’ˆ ë¦¬ë·° ì¼ê´„ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def extract_product_name_from_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ìƒí’ˆëª… ì¶”ì¶œ"""
        # .csv í™•ì¥ì ì œê±°
        product_name = filename.replace('.csv', '')
        # ì–¸ë”ìŠ¤ì½”ì–´ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€ê²½
        product_name = product_name.replace('_', ' ')
        return product_name
    
    def detect_naver_columns(self, df: pd.DataFrame) -> Tuple[str, str, str]:
        """ë„¤ì´ë²„ ë¦¬ë·° ì»¬ëŸ¼ ê°ì§€"""
        # ë„¤ì´ë²„ ë¦¬ë·° í‘œì¤€ ì»¬ëŸ¼ëª…
        text_col = 'content'  # ë¦¬ë·° ë‚´ìš©
        rating_col = 'rating'  # í‰ì 
        product_col = 'product_name'  # ìƒí’ˆëª…
        
        # ì»¬ëŸ¼ëª… í™•ì¸ ë° ëŒ€ì•ˆ ê²€ìƒ‰
        available_cols = df.columns.tolist()
        
        # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì°¾ê¸°
        if 'content' not in available_cols:
            text_candidates = ['review', 'text', 'comment', 'ë‚´ìš©', 'ë¦¬ë·°']
            for candidate in text_candidates:
                if candidate in available_cols:
                    text_col = candidate
                    break
            else:
                # ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ë¥¼ ê°€ì§„ ì»¬ëŸ¼ ì°¾ê¸°
                text_col = self._find_longest_text_column(df)
        
        # í‰ì  ì»¬ëŸ¼ ì°¾ê¸°
        if 'rating' not in available_cols:
            rating_candidates = ['score', 'star', 'rate', 'í‰ì ', 'ë³„ì ']
            for candidate in rating_candidates:
                if candidate in available_cols:
                    rating_col = candidate
                    break
            else:
                rating_col = None
        
        # ìƒí’ˆëª… ì»¬ëŸ¼ ì°¾ê¸°
        if 'product_name' not in available_cols:
            product_candidates = ['name', 'title', 'product', 'ìƒí’ˆëª…', 'ì œí’ˆëª…']
            for candidate in product_candidates:
                if candidate in available_cols:
                    product_col = candidate
                    break
            else:
                product_col = None
        
        return text_col, rating_col, product_col
    
    def _find_longest_text_column(self, df: pd.DataFrame) -> str:
        """ê°€ì¥ ê¸´ í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê°€ì§„ ì»¬ëŸ¼ ì°¾ê¸°"""
        text_columns = []
        for col in df.columns:
            if df[col].dtype == 'object':
                avg_length = df[col].astype(str).str.len().mean()
                if avg_length > 10:  # í‰ê·  10ì ì´ìƒ
                    text_columns.append((col, avg_length))
        
        if text_columns:
            # ê°€ì¥ ê¸´ í‰ê·  ê¸¸ì´ë¥¼ ê°€ì§„ ì»¬ëŸ¼ ë°˜í™˜
            return max(text_columns, key=lambda x: x[1])[0]
        
        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì²« ë²ˆì§¸ object ì»¬ëŸ¼ ë°˜í™˜
        for col in df.columns:
            if df[col].dtype == 'object':
                return col
        
        return df.columns[0]  # ìµœí›„ì˜ ìˆ˜ë‹¨
    
    def analyze_single_review_file(self, file_path: Path) -> Optional[Dict]:
        """ê°œë³„ ë¦¬ë·° íŒŒì¼ ë¶„ì„"""
        try:
            print(f"\nğŸ“ ë¶„ì„ ì¤‘: {file_path.name}")
            
            # 1. ë°ì´í„° ë¡œë“œ
            df = load_csv_data(str(file_path))
            if df is None or len(df) == 0:
                print(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {file_path.name}")
                return None
            
            # 2. ë„¤ì´ë²„ ë¦¬ë·° ì»¬ëŸ¼ ê°ì§€
            text_col, rating_col, product_col = self.detect_naver_columns(df)
            print(f"ğŸ“‹ ê°ì§€ëœ ì»¬ëŸ¼: í…ìŠ¤íŠ¸='{text_col}', í‰ì ='{rating_col}', ìƒí’ˆ='{product_col}'")
            
            # 3. ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
            if not validate_data(df, text_col, rating_col):
                return None
            
            # 4. ê¸°ë³¸ í†µê³„
            total_reviews = len(df)
            avg_review_length = df[text_col].astype(str).str.len().mean()
            avg_rating = df[rating_col].mean() if rating_col and rating_col in df.columns else None
            
            # 5. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            df['cleaned_review'] = df[text_col].fillna('').astype(str)
            df = df[df['cleaned_review'].str.len() > 0]  # ë¹ˆ ë¦¬ë·° ì œê±°
            
            if len(df) == 0:
                print("âŒ ìœ íš¨í•œ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # 6. í˜•íƒœì†Œ ë¶„ì„
            df = self.morphological_analyzer.tokenize_dataframe(df, 'cleaned_review')
            
            if len(df) == 0:
                print("âŒ í† í°í™” í›„ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # 7. ê°ì„± ë¶„ì„
            if rating_col and rating_col in df.columns:
                df = self.sentiment_analyzer.create_sentiment_labels(
                    df, method='rating', rating_column=rating_col
                )
            else:
                # í‰ì ì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°ì„± ë¶„ì„ ì‹œë„
                df = self.sentiment_analyzer.create_sentiment_labels(
                    df, method='learned', tokens_column='tokens'
                )
            
            # 8. í‚¤ì›Œë“œ ì¶”ì¶œ
            texts = df['tokens_str'].tolist()
            if texts:
                self.keyword_extractor.extract_auto_stopwords(texts)
                
                # TF-IDF í‚¤ì›Œë“œ
                tfidf_keywords = self.keyword_extractor.extract_keywords_tfidf(df)
                top_keywords = [word for word, score in tfidf_keywords[:10]]
                
                # ê°ì„±ë³„ í‚¤ì›Œë“œ
                sentiment_keywords = self.keyword_extractor.extract_sentiment_keywords(df)
            else:
                top_keywords = []
                sentiment_keywords = {}
            
            # 9. ê°ì„± ë¶„í¬ ê³„ì‚°
            sentiment_counts = df['sentiment'].value_counts()
            total_sentiment = len(df)
            
            positive_ratio = sentiment_counts.get('positive', 0) / total_sentiment * 100
            negative_ratio = sentiment_counts.get('negative', 0) / total_sentiment * 100
            neutral_ratio = sentiment_counts.get('neutral', 0) / total_sentiment * 100
            
            # 10. ìƒí’ˆëª… ì¶”ì¶œ
            extracted_name = self.extract_product_name_from_filename(file_path.name)
            
            # íŒŒì¼ì—ì„œ ìƒí’ˆëª… ê°€ì ¸ì˜¤ê¸° ì‹œë„
            if product_col and product_col in df.columns:
                product_names = df[product_col].dropna().unique()
                if len(product_names) > 0:
                    file_product_name = product_names[0]
                else:
                    file_product_name = extracted_name
            else:
                file_product_name = extracted_name
            
            # 11. ê²°ê³¼ êµ¬ì„±
            result = {
                'file_name': file_path.name,
                'extracted_name': extracted_name,
                'product_name': file_product_name,
                'total_reviews': total_reviews,
                'valid_reviews': len(df),
                'avg_review_length': round(avg_review_length, 1),
                'avg_rating': round(avg_rating, 2) if avg_rating else None,
                'positive_count': sentiment_counts.get('positive', 0),
                'negative_count': sentiment_counts.get('negative', 0),
                'neutral_count': sentiment_counts.get('neutral', 0),
                'positive_ratio': round(positive_ratio, 1),
                'negative_ratio': round(negative_ratio, 1),
                'neutral_ratio': round(neutral_ratio, 1),
                'top_keywords': ', '.join(top_keywords[:5]),
                'positive_keywords': ', '.join([word for word, score in sentiment_keywords.get('positive', [])[:3]]),
                'negative_keywords': ', '.join([word for word, score in sentiment_keywords.get('negative', [])[:3]]),
                'all_keywords': ', '.join(top_keywords),
                'text_column': text_col,
                'rating_column': rating_col,
                'product_column': product_col
            }
            
            print(f"âœ… ë¶„ì„ ì™„ë£Œ: {file_product_name} ({len(df)}ê°œ ë¦¬ë·°)")
            return result
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨ {file_path.name}: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def run_batch_analysis(self) -> List[Dict]:
        """ì¼ê´„ ë¶„ì„ ì‹¤í–‰"""
        print("\n" + "="*60)
        print("ğŸ”„ ë„¤ì´ë²„ ìƒí’ˆ ë¦¬ë·° ì¼ê´„ ë¶„ì„ ì‹œì‘")
        print("="*60)
        
        # ë¦¬ë·° íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        review_files = list(self.reviews_dir.glob("*.csv"))
        print(f"ğŸ“ ë°œê²¬ëœ ë¦¬ë·° íŒŒì¼: {len(review_files)}ê°œ")
        
        if not review_files:
            print("âŒ ë¦¬ë·° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ê° íŒŒì¼ ë¶„ì„
        self.analysis_results = []
        for i, file_path in enumerate(review_files, 1):
            print(f"\n[{i}/{len(review_files)}] ì²˜ë¦¬ ì¤‘...")
            result = self.analyze_single_review_file(file_path)
            if result:
                self.analysis_results.append(result)
        
        print(f"\nâœ… ì¼ê´„ ë¶„ì„ ì™„ë£Œ: {len(self.analysis_results)}ê°œ ìƒí’ˆ")
        return self.analysis_results
    
    def create_comprehensive_report(self) -> str:
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.analysis_results:
            print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"naver_batch_analysis_{timestamp}.xlsx"
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            
            # 1. ë¶„ì„ ê°œìš” ë° ë©”ì¸ ìš”ì•½ í…Œì´ë¸” (í†µí•©)
            self._create_comprehensive_summary_sheet(writer)
            
            # 2. ìƒì„¸ ë¶„ì„ ê²°ê³¼
            self._create_detailed_analysis_sheet(writer)
            
            # 3. í‚¤ì›Œë“œ ë¶„ì„
            self._create_keyword_analysis_sheet(writer)
            
            # 4. í†µê³„ ìš”ì•½
            self._create_statistics_summary_sheet(writer)
        
        print(f"\nğŸ‰ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“„ íŒŒì¼ ê²½ë¡œ: {output_file}")
        
        return str(output_file)
    
    def _create_comprehensive_summary_sheet(self, writer):
        """ì¢…í•© ìš”ì•½ ì‹œíŠ¸ ìƒì„± (ë¶„ì„ ê°œìš” + ìƒí’ˆ ìš”ì•½)"""
        df_results = pd.DataFrame(self.analysis_results)
        
        # ë¶„ì„ ëŒ€ìƒ ìë£Œ ê°œìš” ë° ìƒí’ˆ ìš”ì•½ì„ í•˜ë‚˜ì˜ ì‹œíŠ¸ì— í†µí•©
        all_data = []
        
        # === 1. ë¶„ì„ ê°œìš” ===
        all_data.extend([
            ['=== ë„¤ì´ë²„ ë¦¬ë·° ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ===', '', '', '', '', ''],
            ['ë¶„ì„ ì¼ì‹œ', datetime.now().strftime("%Y-%m-%d %H:%M:%S"), '', '', '', ''],
            ['ë¶„ì„ ë””ë ‰í† ë¦¬', str(self.reviews_dir), '', '', '', ''],
            ['', '', '', '', '', ''],
            ['[ë¶„ì„ ëŒ€ìƒ ìë£Œ ê°œìš”]', '', '', '', '', ''],
            ['ì´ ë¶„ì„ íŒŒì¼ ìˆ˜', len(df_results), 'ê°œ', '', '', ''],
            ['ì´ ë¦¬ë·° ìˆ˜', df_results['total_reviews'].sum(), 'ê°œ', '', '', ''],
            ['ìœ íš¨ ë¦¬ë·° ìˆ˜', df_results['valid_reviews'].sum(), 'ê°œ', '', '', ''],
            ['ì œê±°ëœ ë¦¬ë·° ìˆ˜', df_results['total_reviews'].sum() - df_results['valid_reviews'].sum(), 'ê°œ', '', '', ''],
            ['í‰ê·  ë¦¬ë·° ìˆ˜ (ìƒí’ˆë‹¹)', f"{df_results['total_reviews'].mean():.1f}", 'ê°œ', '', '', ''],
            ['í‰ê·  ìœ íš¨ ë¦¬ë·° ìˆ˜ (ìƒí’ˆë‹¹)', f"{df_results['valid_reviews'].mean():.1f}", 'ê°œ', '', '', ''],
            ['', '', '', '', '', ''],
            ['[ì „ì²´ ê°ì„± ë¶„í¬]', '', '', '', '', ''],
            ['ì „ì²´ ê¸ì • ë¦¬ë·°', df_results['positive_count'].sum(), 'ê°œ', f"({df_results['positive_ratio'].mean():.1f}%)", '', ''],
            ['ì „ì²´ ë¶€ì • ë¦¬ë·°', df_results['negative_count'].sum(), 'ê°œ', f"({df_results['negative_ratio'].mean():.1f}%)", '', ''],
            ['ì „ì²´ ì¤‘ë¦½ ë¦¬ë·°', df_results['neutral_count'].sum(), 'ê°œ', f"({df_results['neutral_ratio'].mean():.1f}%)", '', ''],
            ['', '', '', '', '', ''],
            ['[í‰ì  ì •ë³´]', '', '', '', '', '']
        ])
        
        # í‰ì  ì •ë³´ê°€ ìˆëŠ” ìƒí’ˆë“¤ì˜ í†µê³„
        rated_products = df_results[df_results['avg_rating'].notna()]
        if len(rated_products) > 0:
            all_data.extend([
                ['í‰ì  ì •ë³´ ìˆëŠ” ìƒí’ˆ ìˆ˜', len(rated_products), 'ê°œ', '', '', ''],
                ['ì „ì²´ í‰ê·  í‰ì ', f"{rated_products['avg_rating'].mean():.2f}", 'ì ', '5ì  ë§Œì ', '', ''],
                ['ìµœê³  í‰ì ', f"{rated_products['avg_rating'].max():.2f}", 'ì ', '', '', ''],
                ['ìµœì € í‰ì ', f"{rated_products['avg_rating'].min():.2f}", 'ì ', '', '', '']
            ])
        else:
            all_data.append(['í‰ì  ì •ë³´', 'ì—†ìŒ', '', '', '', ''])
        
        all_data.extend([
            ['', '', '', '', '', ''],
            ['[ìƒí’ˆë³„ ìš”ì•½ - ê¸ì •ë¹„ìœ¨ ìˆœ]', '', '', '', '', ''],
            ['ìˆœìœ„', 'ìƒí’ˆëª…', 'ì´ë¦¬ë·°ìˆ˜', 'ìœ íš¨ë¦¬ë·°ìˆ˜', 'í‰ê· í‰ì ', 'ê¸ì •ë¹„ìœ¨(%)']
        ])
        
        # ìƒí’ˆ ìš”ì•½ (ê¸ì •ë¹„ìœ¨ ìˆœìœ¼ë¡œ ì •ë ¬)
        summary_df = df_results.sort_values('positive_ratio', ascending=False)
        
        for i, (idx, row) in enumerate(summary_df.iterrows(), 1):
            product_name = row['product_name'][:40] + "..." if len(row['product_name']) > 40 else row['product_name']
            avg_rating = f"{row['avg_rating']:.2f}" if pd.notna(row['avg_rating']) else 'ì—†ìŒ'
            all_data.append([
                i,
                product_name,
                row['total_reviews'],
                row['valid_reviews'],
                avg_rating,
                f"{row['positive_ratio']:.1f}%"
            ])
        
        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
        comprehensive_df = pd.DataFrame(all_data, columns=['êµ¬ë¶„', 'í•­ëª©', 'ê°’', 'ì¶”ê°€ì •ë³´1', 'ì¶”ê°€ì •ë³´2', 'ì¶”ê°€ì •ë³´3'])
        comprehensive_df.to_excel(writer, sheet_name='1_ì¢…í•©ìš”ì•½', index=False)
        
        # ì›Œí¬ì‹œíŠ¸ ìŠ¤íƒ€ì¼ë§
        worksheet = writer.sheets['1_ì¢…í•©ìš”ì•½']
        worksheet.column_dimensions['A'].width = 15
        worksheet.column_dimensions['B'].width = 45
        worksheet.column_dimensions['C'].width = 12
        worksheet.column_dimensions['D'].width = 15
        worksheet.column_dimensions['E'].width = 15
        worksheet.column_dimensions['F'].width = 15
        
        print("âœ… ì¢…í•© ìš”ì•½ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def _create_detailed_analysis_sheet(self, writer):
        """ìƒì„¸ ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        df_results = pd.DataFrame(self.analysis_results)
        
        detailed_columns = [
            'product_name', 'file_name', 'total_reviews', 'valid_reviews', 
            'avg_review_length', 'avg_rating', 'positive_count', 'negative_count', 
            'neutral_count', 'positive_ratio', 'negative_ratio', 'neutral_ratio',
            'all_keywords', 'text_column', 'rating_column'
        ]
        
        detailed_df = df_results[detailed_columns].copy()
        detailed_df.columns = [
            'ìƒí’ˆëª…', 'íŒŒì¼ëª…', 'ì´ ë¦¬ë·°ìˆ˜', 'ìœ íš¨ ë¦¬ë·°ìˆ˜', 'í‰ê·  ë¦¬ë·°ê¸¸ì´',
            'í‰ê· í‰ì ', 'ê¸ì •ìˆ˜', 'ë¶€ì •ìˆ˜', 'ì¤‘ë¦½ìˆ˜', 'ê¸ì •ë¹„ìœ¨(%)', 
            'ë¶€ì •ë¹„ìœ¨(%)', 'ì¤‘ë¦½ë¹„ìœ¨(%)', 'ì „ì²´í‚¤ì›Œë“œ', 'í…ìŠ¤íŠ¸ì»¬ëŸ¼', 'í‰ì ì»¬ëŸ¼'
        ]
        
        detailed_df.to_excel(writer, sheet_name='2_ìƒì„¸ë¶„ì„', index=False)
        print("âœ… ìƒì„¸ ë¶„ì„ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def _create_keyword_analysis_sheet(self, writer):
        """í‚¤ì›Œë“œ ë¶„ì„ ì‹œíŠ¸ ìƒì„±"""
        df_results = pd.DataFrame(self.analysis_results)
        
        # ìƒí’ˆë³„ í‚¤ì›Œë“œ ë¶„ì„
        keyword_data = []
        
        for idx, row in df_results.iterrows():
            keyword_data.append({
                'ìƒí’ˆëª…': row['product_name'],
                'ì´ ë¦¬ë·°ìˆ˜': row['total_reviews'],
                'ê¸ì •ë¹„ìœ¨': row['positive_ratio'],
                'ì£¼ìš” í‚¤ì›Œë“œ': row['top_keywords'],
                'ê¸ì • í‚¤ì›Œë“œ': row['positive_keywords'],
                'ë¶€ì • í‚¤ì›Œë“œ': row['negative_keywords']
            })
        
        keyword_df = pd.DataFrame(keyword_data)
        keyword_df = keyword_df.sort_values('ê¸ì •ë¹„ìœ¨', ascending=False)
        keyword_df.to_excel(writer, sheet_name='3_í‚¤ì›Œë“œë¶„ì„', index=False)
        print("âœ… í‚¤ì›Œë“œ ë¶„ì„ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def _create_statistics_summary_sheet(self, writer):
        """í†µê³„ ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        df_results = pd.DataFrame(self.analysis_results)
        
        stats_data = [
            ['ì „ì²´ í†µê³„', '', ''],
            ['ë¶„ì„ëœ ìƒí’ˆ ìˆ˜', len(df_results), 'ê°œ'],
            ['ì´ ë¦¬ë·° ìˆ˜', df_results['total_reviews'].sum(), 'ê°œ'],
            ['ì´ ìœ íš¨ ë¦¬ë·° ìˆ˜', df_results['valid_reviews'].sum(), 'ê°œ'],
            ['í‰ê·  ë¦¬ë·° ìˆ˜ (ìƒí’ˆë‹¹)', df_results['total_reviews'].mean(), 'ê°œ'],
            ['ì „ì²´ í‰ê·  ê¸ì •ë¹„ìœ¨', df_results['positive_ratio'].mean(), '%'],
            ['ì „ì²´ í‰ê·  ë¶€ì •ë¹„ìœ¨', df_results['negative_ratio'].mean(), '%'],
            ['', '', ''],
            ['TOP 5 ê¸ì • ìƒí’ˆ', '', ''],
        ]
        
        # TOP 5 ê¸ì • ìƒí’ˆ
        top_positive = df_results.nlargest(5, 'positive_ratio')
        for idx, row in top_positive.iterrows():
            stats_data.append([
                row['product_name'][:30], 
                f"{row['positive_ratio']}%", 
                f"{row['total_reviews']}ê°œ ë¦¬ë·°"
            ])
        
        stats_data.extend([
            ['', '', ''],
            ['TOP 5 ë¶€ì • ìƒí’ˆ', '', ''],
        ])
        
        # TOP 5 ë¶€ì • ìƒí’ˆ
        top_negative = df_results.nlargest(5, 'negative_ratio')
        for idx, row in top_negative.iterrows():
            stats_data.append([
                row['product_name'][:30], 
                f"{row['negative_ratio']}%", 
                f"{row['total_reviews']}ê°œ ë¦¬ë·°"
            ])
        
        stats_df = pd.DataFrame(stats_data, columns=['í•­ëª©', 'ê°’', 'ë‹¨ìœ„'])
        stats_df.to_excel(writer, sheet_name='4_í†µê³„ìš”ì•½', index=False)
        print("âœ… í†µê³„ ìš”ì•½ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
    
    def print_summary(self):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.analysis_results:
            return
        
        df_results = pd.DataFrame(self.analysis_results)
        
        print("\n" + "="*60)
        print("ğŸ“Š ë„¤ì´ë²„ ìƒí’ˆ ë¦¬ë·° ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        print(f"ğŸ“ ë¶„ì„ ë””ë ‰í† ë¦¬: {self.reviews_dir}")
        print(f"ğŸ”¢ ë¶„ì„ëœ ìƒí’ˆ ìˆ˜: {len(df_results)}ê°œ")
        print(f"ğŸ“ ì´ ë¦¬ë·° ìˆ˜: {df_results['total_reviews'].sum():,}ê°œ")
        print(f"ğŸ“ ìœ íš¨ ë¦¬ë·° ìˆ˜: {df_results['valid_reviews'].sum():,}ê°œ")
        print(f"ğŸ—‘ï¸ ì œê±°ëœ ë¦¬ë·° ìˆ˜: {df_results['total_reviews'].sum() - df_results['valid_reviews'].sum():,}ê°œ")
        print(f"â­ ì „ì²´ í‰ê·  ê¸ì •ë¹„ìœ¨: {df_results['positive_ratio'].mean():.1f}%")
        print(f"â­ ì „ì²´ í‰ê·  ë¶€ì •ë¹„ìœ¨: {df_results['negative_ratio'].mean():.1f}%")
        
        # í‰ì  ì •ë³´ê°€ ìˆëŠ” ìƒí’ˆë“¤ì˜ í‰ê· 
        rated_products = df_results[df_results['avg_rating'].notna()]
        if len(rated_products) > 0:
            print(f"â­ í‰ê·  í‰ì : {rated_products['avg_rating'].mean():.2f} (í‰ì  ì •ë³´ ìˆëŠ” {len(rated_products)}ê°œ ìƒí’ˆ)")
        else:
            print(f"â­ í‰ì  ì •ë³´: ì—†ìŒ")
        
        # ì»¬ëŸ¼ ì •ë³´ ìš”ì•½
        unique_text_cols = df_results['text_column'].unique()
        unique_rating_cols = df_results['rating_column'].unique()
        print(f"\nğŸ“‹ ë°ì´í„° êµ¬ì¡°:")
        print(f"   í…ìŠ¤íŠ¸ ì»¬ëŸ¼: {list(unique_text_cols)}")
        print(f"   í‰ì  ì»¬ëŸ¼: {list(unique_rating_cols)}")
        
        print(f"\nğŸ† ê¸ì •ë¹„ìœ¨ TOP 5 ìƒí’ˆ:")
        top_products = df_results.nlargest(5, 'positive_ratio')
        for idx, row in top_products.iterrows():
            print(f"   {row['product_name'][:40]:40} "
                  f"ê¸ì •: {row['positive_ratio']}% ({row['total_reviews']}ê°œ ë¦¬ë·°)")
        
        print(f"\nğŸ“‰ ë¶€ì •ë¹„ìœ¨ TOP 5 ìƒí’ˆ:")
        bottom_products = df_results.nlargest(5, 'negative_ratio')
        for idx, row in bottom_products.iterrows():
            print(f"   {row['product_name'][:40]:40} "
                  f"ë¶€ì •: {row['negative_ratio']}% ({row['total_reviews']}ê°œ ë¦¬ë·°)")
        
        print("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ê²½ë¡œ ì„¤ì •
    reviews_dir = "/Users/brich/Desktop/marketcrawler/crawler/operators/output/naver_reviews1"
    output_dir = "/Users/brich/Desktop/marketcrawler/output"
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
    analyzer = NaverReviewAnalyzer(reviews_dir, output_dir)
    
    # ì¼ê´„ ë¶„ì„ ì‹¤í–‰
    results = analyzer.run_batch_analysis()
    
    if results:
        # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
        output_file = analyzer.create_comprehensive_report()
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        analyzer.print_summary()
        
        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {output_file}")
    else:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()