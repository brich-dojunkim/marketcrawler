# core/sentiment.py
"""ê°ì„± ë¶„ì„ ëª¨ë“ˆ - Transformers í†µí•©"""

import pandas as pd
import numpy as np
from typing import List, Dict, Optional
from sklearn.feature_extraction.text import TfidfVectorizer

class SentimentAnalyzer:
    """ê°ì„± ë¶„ì„ í´ë˜ìŠ¤ - ë‹¤ì¤‘ ë°©ì‹ ì§€ì›"""
    
    def __init__(self, use_transformers: bool = True) -> None:
        """
        ê°ì„± ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            use_transformers: Transformers ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
        """
        self.learned_patterns = {'positive': [], 'negative': []}
        self.is_trained = False
        self.transformers_pipeline = None
        
        # Transformers ì´ˆê¸°í™”
        if use_transformers:
            self._initialize_transformers()
    
    def _initialize_transformers(self) -> None:
        """Transformers ëª¨ë¸ ì´ˆê¸°í™” (íƒ€ì… íŒíŠ¸ ì¶”ê°€)"""
        try:
            # ë™ì  importë¡œ ì˜ì¡´ì„± ë¬¸ì œ í•´ê²°
            import torch
            from transformers import pipeline
            import os
            
            # í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ê²½ê³  ì œê±°)
            os.environ["TOKENIZERS_PARALLELISM"] = "false"
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"ğŸ§  Transformers ê°ì„± ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘... (Device: {device})")
            print(f"ğŸ“¦ PyTorch ë²„ì „: {torch.__version__}")
            
            # safetensors ì§€ì› ëª¨ë¸ ìš°ì„ 
            model_options = [
                "klue/roberta-base",  # í˜„ì¬ ì„±ê³µí•œ ëª¨ë¸
                "cardiffnlp/twitter-xlm-roberta-base-sentiment",  # ì•ˆì •ì 
                "nlptown/bert-base-multilingual-uncased-sentiment"  # ëŒ€ì•ˆ
            ]
            
            for model_name in model_options:
                try:
                    print(f"ğŸ”„ {model_name} ë¡œë“œ ì‹œë„ ì¤‘...")
                    
                    self.transformers_pipeline = pipeline(
                        "sentiment-analysis",
                        model=model_name,
                        device=0 if device == "cuda" else -1,
                        use_fast=True,
                        return_all_scores=False
                    )
                    print(f"âœ… Transformers ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_name}")
                    break
                    
                except Exception as e:
                    print(f"âš ï¸ {model_name} ë¡œë“œ ì‹¤íŒ¨: {str(e)[:100]}...")
                    continue
            
            if not self.transformers_pipeline:
                print("âŒ ëª¨ë“  Transformers ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
                print("ğŸ’¡ í•´ê²° ë°©ë²•: pip install torch>=2.6.0")
                
        except ImportError as e:
            print(f"âš ï¸ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ì„¤ì¹˜ ë°©ë²•: pip install torch transformers")
        except Exception as e:
            print(f"âŒ Transformers ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def learn_patterns_from_ratings(self, df: pd.DataFrame, text_col: str = 'tokens_str', 
                                  rating_col: str = 'rating') -> Dict[str, List[str]]:
        """í‰ì  ë°ì´í„°ë¡œë¶€í„° ê°ì„± íŒ¨í„´ í•™ìŠµ"""
        if rating_col not in df.columns:
            print("âš ï¸ í‰ì  ì»¬ëŸ¼ì´ ì—†ì–´ íŒ¨í„´ í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {}
        
        print("ğŸ“– í‰ì  ë°ì´í„°ë¡œë¶€í„° ê°ì„± íŒ¨í„´ í•™ìŠµ ì¤‘...")
        
        # í‰ì  ê¸°ì¤€ìœ¼ë¡œ ê¸ì •/ë¶€ì • ë¶„ë¥˜
        high_rating_texts = df[df[rating_col] >= 4][text_col].dropna()
        low_rating_texts = df[df[rating_col] <= 2][text_col].dropna()
        
        if len(high_rating_texts) == 0 or len(low_rating_texts) == 0:
            print("âš ï¸ ì¶©ë¶„í•œ ê¸ì •/ë¶€ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        try:
            # ê¸ì • íŒ¨í„´ ì¶”ì¶œ
            positive_text = ' '.join(high_rating_texts)
            pos_vectorizer = TfidfVectorizer(max_features=30, token_pattern=r'\b\w+\b')
            pos_vectorizer.fit_transform([positive_text])
            self.learned_patterns['positive'] = list(pos_vectorizer.get_feature_names_out())
            
            # ë¶€ì • íŒ¨í„´ ì¶”ì¶œ  
            negative_text = ' '.join(low_rating_texts)
            if len(negative_text.strip()) > 0:
                neg_vectorizer = TfidfVectorizer(max_features=20, token_pattern=r'\b\w+\b')
                neg_vectorizer.fit_transform([negative_text])
                self.learned_patterns['negative'] = list(neg_vectorizer.get_feature_names_out())
            
            self.is_trained = True
            
            print(f"âœ… ê°ì„± íŒ¨í„´ í•™ìŠµ ì™„ë£Œ:")
            print(f"   ê¸ì • íŒ¨í„´: {len(self.learned_patterns['positive'])}ê°œ")
            print(f"   ë¶€ì • íŒ¨í„´: {len(self.learned_patterns['negative'])}ê°œ")
            
            return self.learned_patterns
            
        except Exception as e:
            print(f"âŒ ê°ì„± íŒ¨í„´ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {}
    
    def analyze_sentiment_rating_based(self, rating: float, threshold: float = 3.0) -> str:
        """í‰ì  ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        if rating > threshold:
            return 'positive'
        elif rating < threshold:
            return 'negative'
        else:
            return 'neutral'
    
    def analyze_sentiment_learned_patterns(self, tokens: List[str]) -> str:
        """í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        if not self.is_trained:
            return 'neutral'
        
        pos_score = sum(1 for token in tokens if token in self.learned_patterns['positive'])
        neg_score = sum(1 for token in tokens if token in self.learned_patterns['negative'])
        
        if pos_score > neg_score:
            return 'positive'
        elif neg_score > pos_score:
            return 'negative'
        else:
            return 'neutral'
    
    def analyze_sentiment_transformers(self, text: str) -> Dict[str, float]:
        """Transformers ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        if not self.transformers_pipeline or not text.strip():
            return {'label': 'neutral', 'confidence': 0.0}
        
        try:
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
            text = text[:512]
            result = self.transformers_pipeline(text)
            
            # ê²°ê³¼ ì •ê·œí™”
            label = result[0]['label'].lower()
            confidence = result[0]['score']
            
            # ë¼ë²¨ ë§¤í•‘
            label_mapping = {
                'positive': 'positive',
                'negative': 'negative',
                'neutral': 'neutral',
                'label_0': 'negative',
                'label_1': 'neutral',
                'label_2': 'positive'
            }
            
            mapped_label = label_mapping.get(label, 'neutral')
            
            return {'label': mapped_label, 'confidence': confidence}
            
        except Exception as e:
            print(f"Transformers ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {'label': 'neutral', 'confidence': 0.0}
    
    def create_sentiment_labels(self, df: pd.DataFrame, method: str = 'rating', 
                              tokens_column: str = 'tokens', 
                              rating_column: Optional[str] = None,
                              text_column: Optional[str] = None) -> pd.DataFrame:
        """
        ê°ì„± ë¼ë²¨ ìƒì„± (ë‹¤ì¤‘ ë°©ì‹ ì§€ì›)
        """
        print(f"ğŸ¯ {method} ë°©ì‹ìœ¼ë¡œ ê°ì„± ë¶„ì„ ì¤‘...")
        
        df = df.copy()
        
        if method == 'transformers' and self.transformers_pipeline and text_column:
            # Transformers ê¸°ë°˜ ê°ì„± ë¶„ì„
            print("ğŸ§  Transformers ê¸°ë°˜ ê°ì„± ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            
            texts = df[text_column].fillna("").tolist()
            results = []
            
            # ë°°ì¹˜ ì²˜ë¦¬
            batch_size = 16
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i+batch_size]
                batch_results = [self.analyze_sentiment_transformers(text) for text in batch_texts]
                results.extend(batch_results)
            
            df['sentiment'] = [result['label'] for result in results]
            df['confidence_transformers'] = [result['confidence'] for result in results]
            
        elif method == 'ensemble' and text_column and rating_column:
            # ì•™ìƒë¸”: í‰ì  + (Transformers) + í•™ìŠµëœ íŒ¨í„´
            print("ğŸ¯ ì•™ìƒë¸” ê°ì„± ë¶„ì„ ì‹¤í–‰ ì¤‘...")
            
            # 1. í‰ì  ê¸°ë°˜ (ê¸°ë³¸)
            df['sentiment_rating'] = df[rating_column].apply(self.analyze_sentiment_rating_based)
            
            # 2. Transformers ê¸°ë°˜ (ìˆëŠ” ê²½ìš°ë§Œ)
            if self.transformers_pipeline:
                texts = df[text_column].fillna("").tolist()
                transformers_results = [self.analyze_sentiment_transformers(text) for text in texts]
                df['sentiment_transformers'] = [result['label'] for result in transformers_results]
                df['confidence_transformers'] = [result['confidence'] for result in transformers_results]
                print("âœ… Transformers ê°ì„± ë¶„ì„ ì™„ë£Œ")
            else:
                print("âš ï¸ Transformers ì‚¬ìš© ë¶ˆê°€ - í‰ì  ê¸°ë°˜ë§Œ ì‚¬ìš©")
                df['sentiment_transformers'] = 'neutral'
                df['confidence_transformers'] = 0.0
            
            # 3. í•™ìŠµëœ íŒ¨í„´
            if not self.is_trained:
                self.learn_patterns_from_ratings(df, 'tokens_str', rating_column)
            
            df['sentiment_learned'] = df[tokens_column].apply(
                lambda x: self.analyze_sentiment_learned_patterns(x if isinstance(x, list) else x.split())
            )
            
            # 4. ì•™ìƒë¸” ê²°í•©
            if self.transformers_pipeline:
                # Transformers ìˆëŠ” ê²½ìš°: ê°€ì¤‘ íˆ¬í‘œ
                df['sentiment'] = df.apply(self._ensemble_sentiment, axis=1)
            else:
                # Transformers ì—†ëŠ” ê²½ìš°: í‰ì  + íŒ¨í„´
                df['sentiment'] = df.apply(
                    lambda row: row['sentiment_learned'] if row['sentiment_rating'] == 'neutral' 
                               else row['sentiment_rating'], axis=1
                )
            
        elif method == 'rating' and rating_column and rating_column in df.columns:
            # í‰ì  ê¸°ë°˜ë§Œ
            df['sentiment'] = df[rating_column].apply(self.analyze_sentiment_rating_based)
            
        elif method == 'learned' and tokens_column in df.columns:
            # í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ë§Œ
            if not self.is_trained:
                self.learn_patterns_from_ratings(df, 'tokens_str', rating_column)
            
            df['sentiment'] = df[tokens_column].apply(
                lambda x: self.analyze_sentiment_learned_patterns(x if isinstance(x, list) else x.split())
            )
        else:
            # ê¸°ë³¸ê°’
            df['sentiment'] = 'neutral'
        
        print("âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ")
        if 'sentiment' in df.columns:
            sentiment_counts = df['sentiment'].value_counts()
            print(sentiment_counts)
            
            # Transformers ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‰ê·  ì‹ ë¢°ë„ë„ ì¶œë ¥
            if 'confidence_transformers' in df.columns:
                avg_confidence = df['confidence_transformers'].mean()
                print(f"í‰ê·  Transformers ì‹ ë¢°ë„: {avg_confidence:.3f}")
        
        return df
    
    def _ensemble_sentiment(self, row) -> str:
        """ì•™ìƒë¸” ê°ì„± ê²°ì • (ê°€ì¤‘ íˆ¬í‘œ)"""
        votes = []
        weights = []
        
        # í‰ì  ê¸°ë°˜ (ê°€ì¤‘ì¹˜: 0.4)
        if 'sentiment_rating' in row:
            votes.append(row['sentiment_rating'])
            weights.append(0.4)
        
        # Transformers (ê°€ì¤‘ì¹˜: ì‹ ë¢°ë„ ê¸°ë°˜)
        if 'sentiment_transformers' in row and 'confidence_transformers' in row:
            votes.append(row['sentiment_transformers'])
            weights.append(row['confidence_transformers'] * 0.4)
        
        # í•™ìŠµëœ íŒ¨í„´ (ê°€ì¤‘ì¹˜: 0.2)
        if 'sentiment_learned' in row:
            votes.append(row['sentiment_learned'])
            weights.append(0.2)
        
        if not votes:
            return 'neutral'
        
        # ê°€ì¤‘ íˆ¬í‘œ
        sentiment_scores = {'positive': 0, 'negative': 0, 'neutral': 0}
        
        for vote, weight in zip(votes, weights):
            sentiment_scores[vote] += weight
        
        # ìµœê³  ì ìˆ˜ ê°ì„± ë°˜í™˜
        return max(sentiment_scores, key=sentiment_scores.get)
    
    def compare_sentiment_methods(self, df: pd.DataFrame) -> Dict:
        """ê°ì„± ë¶„ì„ ë°©ë²•ë“¤ ë¹„êµ"""
        comparison = {}
        
        if 'sentiment_rating' in df.columns and 'sentiment_transformers' in df.columns:
            # í‰ì  vs Transformers ì¼ì¹˜ë„
            agreement = (df['sentiment_rating'] == df['sentiment_transformers']).mean()
            comparison['rating_vs_transformers'] = agreement
            
            # í¬ë¡œìŠ¤íƒ­
            crosstab = pd.crosstab(df['sentiment_rating'], df['sentiment_transformers'])
            comparison['crosstab'] = crosstab
            
            print(f"ğŸ“Š í‰ì  vs Transformers ì¼ì¹˜ë„: {agreement:.3f}")
        
        return comparison
    
    def get_sentiment_statistics(self, df: pd.DataFrame, sentiment_column: str = 'sentiment') -> Dict:
        """ê°ì„± ë¶„ì„ í†µê³„ ë°˜í™˜"""
        sentiment_counts = df[sentiment_column].value_counts()
        total_count = len(df)
        
        stats = {}
        for sentiment in ['positive', 'negative', 'neutral']:
            count = sentiment_counts.get(sentiment, 0)
            ratio = count / total_count * 100
            stats[sentiment] = {
                'count': count,
                'ratio': ratio
            }
        
        return stats
    
    def get_learned_patterns(self) -> Dict[str, List[str]]:
        """í•™ìŠµëœ íŒ¨í„´ ë°˜í™˜"""
        return self.learned_patterns