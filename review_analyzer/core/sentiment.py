# core/sentiment.py
"""ê°ì„± ë¶„ì„ ëª¨ë“ˆ - ë°ì´í„° ê¸°ë°˜ ì ‘ê·¼"""

import pandas as pd
import numpy as np
from typing import List, Dict
from sklearn.feature_extraction.text import TfidfVectorizer

class SentimentAnalyzer:
    """ê°ì„± ë¶„ì„ í´ë˜ìŠ¤ - ë°ì´í„° ê¸°ë°˜"""
    
    def __init__(self):
        """ê°ì„± ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        self.learned_patterns = {'positive': [], 'negative': []}
        self.is_trained = False
    
    def learn_patterns_from_ratings(self, df: pd.DataFrame, text_col: str = 'tokens_str', 
                                  rating_col: str = 'rating') -> Dict:
        """
        í‰ì  ë°ì´í„°ë¡œë¶€í„° ê°ì„± íŒ¨í„´ í•™ìŠµ
        
        Args:
            df: ì…ë ¥ DataFrame
            text_col: í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…
            rating_col: í‰ì  ì»¬ëŸ¼ëª…
            
        Returns:
            í•™ìŠµëœ íŒ¨í„´ ë”•ì…”ë„ˆë¦¬
        """
        if rating_col not in df.columns:
            print("âš ï¸ í‰ì  ì»¬ëŸ¼ì´ ì—†ì–´ íŒ¨í„´ í•™ìŠµì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {}
        
        print("ğŸ“– í‰ì  ë°ì´í„°ë¡œë¶€í„° ê°ì„± íŒ¨í„´ í•™ìŠµ ì¤‘...")
        
        # í‰ì  ê¸°ì¤€ìœ¼ë¡œ ê¸ì •/ë¶€ì • ë¶„ë¥˜
        high_rating_texts = df[df[rating_col] >= 4][text_col].dropna()
        low_rating_texts = df[df[rating_col] <= 2][text_col].dropna()
        
        if len(high_rating_texts) == 0 or len(low_rating_texts) == 0:
            print("âš ï¸ ì¶©ë¶„í•œ ê¸ì •/ë¶€ì • ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}
        
        try:
            # ê¸ì • íŒ¨í„´ ì¶”ì¶œ
            positive_text = ' '.join(high_rating_texts)
            pos_vectorizer = TfidfVectorizer(max_features=30, token_pattern=r'\b\w+\b')
            pos_tfidf = pos_vectorizer.fit_transform([positive_text])
            self.learned_patterns['positive'] = list(pos_vectorizer.get_feature_names_out())
            
            # ë¶€ì • íŒ¨í„´ ì¶”ì¶œ  
            negative_text = ' '.join(low_rating_texts)
            if len(negative_text.strip()) > 0:
                neg_vectorizer = TfidfVectorizer(max_features=20, token_pattern=r'\b\w+\b')
                neg_tfidf = neg_vectorizer.fit_transform([negative_text])
                self.learned_patterns['negative'] = list(neg_vectorizer.get_feature_names_out())
            
            self.is_trained = True
            
            print(f"âœ… ê°ì„± íŒ¨í„´ í•™ìŠµ ì™„ë£Œ:")
            print(f"   ê¸ì • íŒ¨í„´: {len(self.learned_patterns['positive'])}ê°œ")
            print(f"   ë¶€ì • íŒ¨í„´: {len(self.learned_patterns['negative'])}ê°œ")
            
            return self.learned_patterns
            
        except Exception as e:
            print(f"âŒ ê°ì„± íŒ¨í„´ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return {}
    
    def analyze_sentiment_rating_based(self, rating: float, threshold: float = 3.0) -> str:
        """
        í‰ì  ê¸°ë°˜ ê°ì„± ë¶„ì„ (ê°€ì¥ ê°ê´€ì )
        
        Args:
            rating: í‰ì  ê°’
            threshold: ì¤‘ë¦½ ê¸°ì¤€ì 
            
        Returns:
            ê°ì„± ë¼ë²¨
        """
        if rating > threshold:
            return 'positive'
        elif rating < threshold:
            return 'negative'
        else:
            return 'neutral'
    
    def analyze_sentiment_learned_patterns(self, tokens: List[str]) -> str:
        """
        í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜ ê°ì„± ë¶„ì„
        
        Args:
            tokens: í† í°í™”ëœ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê°ì„± ë¼ë²¨
        """
        if not self.is_trained:
            return 'neutral'
        
        pos_score = sum(1 for token in tokens if token in self.learned_patterns['positive'])
        neg_score = sum(1 for token in tokens if token in self.learned_patterns['negative'])
        
        if pos_score > neg_score:
            return 'positive'
        elif neg_score > pos_score:
            return 'negative'
        else:
            return 'neutral'
    
    def create_sentiment_labels(self, df: pd.DataFrame, method: str = 'rating', 
                              tokens_column: str = 'tokens', 
                              rating_column: str = None) -> pd.DataFrame:
        """
        ê°ì„± ë¼ë²¨ ìƒì„±
        
        Args:
            df: ì…ë ¥ DataFrame
            method: ê°ì„± ë¶„ì„ ë°©ë²• ('rating', 'learned', 'hybrid')
            tokens_column: í† í° ì»¬ëŸ¼ëª…
            rating_column: í‰ì  ì»¬ëŸ¼ëª…
            
        Returns:
            ê°ì„± ë¼ë²¨ì´ ì¶”ê°€ëœ DataFrame
        """
        print(f"ğŸ¯ {method} ë°©ì‹ìœ¼ë¡œ ê°ì„± ë¶„ì„ ì¤‘...")
        
        df = df.copy()
        
        if method == 'rating' and rating_column and rating_column in df.columns:
            # í‰ì  ê¸°ë°˜ (ê°€ì¥ ê°ê´€ì )
            df['sentiment'] = df[rating_column].apply(self.analyze_sentiment_rating_based)
            
        elif method == 'learned' and tokens_column in df.columns:
            # í•™ìŠµëœ íŒ¨í„´ ê¸°ë°˜
            if not self.is_trained:
                # íŒ¨í„´ í•™ìŠµ ë¨¼ì € ì‹¤í–‰
                self.learn_patterns_from_ratings(df, 'tokens_str', rating_column)
            
            df['sentiment'] = df[tokens_column].apply(
                lambda x: self.analyze_sentiment_learned_patterns(x if isinstance(x, list) else x.split())
            )
            
        elif method == 'hybrid' and rating_column and tokens_column:
            # í•˜ì´ë¸Œë¦¬ë“œ: í‰ì  ìš°ì„ , íŒ¨í„´ ë³´ì¡°
            df['sentiment_rating'] = df[rating_column].apply(self.analyze_sentiment_rating_based)
            
            if not self.is_trained:
                self.learn_patterns_from_ratings(df, 'tokens_str', rating_column)
            
            df['sentiment_learned'] = df[tokens_column].apply(
                lambda x: self.analyze_sentiment_learned_patterns(x if isinstance(x, list) else x.split())
            )
            
            # í‰ì  ê¸°ë°˜ì„ ë©”ì¸ìœ¼ë¡œ, ì¤‘ë¦½ì¸ ê²½ìš°ë§Œ íŒ¨í„´ ê¸°ë°˜ ì‚¬ìš©
            df['sentiment'] = df.apply(
                lambda row: row['sentiment_learned'] if row['sentiment_rating'] == 'neutral' 
                           else row['sentiment_rating'], axis=1
            )
        else:
            # ê¸°ë³¸ê°’
            df['sentiment'] = 'neutral'
        
        print("âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ")
        print(df['sentiment'].value_counts())
        
        return df
    
    def get_sentiment_statistics(self, df: pd.DataFrame, sentiment_column: str = 'sentiment') -> Dict:
        """
        ê°ì„± ë¶„ì„ í†µê³„ ë°˜í™˜
        
        Args:
            df: ì…ë ¥ DataFrame
            sentiment_column: ê°ì„± ì»¬ëŸ¼ëª…
            
        Returns:
            ê°ì„± í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        sentiment_counts = df[sentiment_column].value_counts()
        total_count = len(df)
        
        stats = {}
        for sentiment in ['positive', 'negative', 'neutral']:
            count = sentiment_counts.get(sentiment, 0)
            ratio = count / total_count * 100
            stats[sentiment] = {
                'count': count,
                'ratio': ratio
            }
        
        return stats
    
    def get_learned_patterns(self) -> Dict:
        """í•™ìŠµëœ íŒ¨í„´ ë°˜í™˜"""
        return self.learned_patterns