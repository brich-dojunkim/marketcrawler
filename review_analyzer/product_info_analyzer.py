# product_info_analyzer.py
"""
ë„¤ì´ë²„ ìƒí’ˆ ì •ë³´ í‚¤ì›Œë“œ ë° ê°ì„± ë¶„ì„ê¸°
ìƒí’ˆëª…, ê°€ê²©, í‰ì  ë“±ì„ ë¶„ì„í•˜ì—¬ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ê°ì„± ë¶„ì„ ìˆ˜í–‰
"""

import pandas as pd
import numpy as np
import re
from typing import Dict, List, Tuple, Optional
from collections import Counter
from datetime import datetime
from pathlib import Path
import warnings
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

warnings.filterwarnings('ignore')

class ProductInfoAnalyzer:
    """ìƒí’ˆ ì •ë³´ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir: str = "/Users/brich/Desktop/marketcrawler/output"):
        """
        Args:
            output_dir: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥ìš©
        self.analysis_results = []
        
        # ë™ì ìœ¼ë¡œ ì¶”ì¶œë  ë°ì´í„°
        self.extracted_brands = set()
        self.extracted_keywords = []
        self.category_clusters = {}
        
        print("ğŸš€ ìƒí’ˆ ì •ë³´ ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def preprocess_product_name(self, product_name: str) -> str:
        """ìƒí’ˆëª… ì „ì²˜ë¦¬"""
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ê³µë°±ìœ¼ë¡œ ë³€ê²½
        cleaned = re.sub(r'[^\w\sê°€-í£]', ' ', product_name)
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        cleaned = re.sub(r'\s+', ' ', cleaned)
        return cleaned.strip()
    
    def extract_brands_from_data(self, df: pd.DataFrame) -> List[str]:
        """ë°ì´í„°ì—ì„œ ë¸Œëœë“œëª… ìë™ ì¶”ì¶œ"""
        print("ğŸ·ï¸ ë¸Œëœë“œëª… ìë™ ì¶”ì¶œ ì¤‘...")
        
        all_words = []
        for name in df['name']:
            # ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ (ë¸Œëœë“œì¼ ê°€ëŠ¥ì„± ë†’ìŒ)
            bracket_matches = re.findall(r'\(([^)]+)\)', name)
            all_words.extend(bracket_matches)
            
            # ì²« ë²ˆì§¸ ë‹¨ì–´ë“¤ (ë¸Œëœë“œì¼ ê°€ëŠ¥ì„±)
            words = self.preprocess_product_name(name).split()
            if words:
                all_words.append(words[0])
        
        # ë¹ˆë„ ê³„ì‚°í•´ì„œ ìì£¼ ë‚˜ì˜¤ëŠ” ë¸Œëœë“œë“¤ ì¶”ì¶œ
        word_counts = Counter(all_words)
        
        # ìµœì†Œ 2ë²ˆ ì´ìƒ ë‚˜ì˜¤ê³ , í•œê¸€ì´ í¬í•¨ëœ ë‹¨ì–´ë“¤ì„ ë¸Œëœë“œë¡œ ì¸ì •
        brands = []
        for word, count in word_counts.items():
            if count >= 2 and len(word) >= 2 and re.search(r'[ê°€-í£]', word):
                brands.append(word)
        
        self.extracted_brands = set(brands)
        print(f"âœ… ì¶”ì¶œëœ ë¸Œëœë“œ: {len(brands)}ê°œ - {brands[:10]}")
        return brands
    
    def extract_keywords_tfidf(self, df: pd.DataFrame, max_features: int = 50) -> List[Tuple[str, float]]:
        """TF-IDF ê¸°ë°˜ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ"""
        print("ğŸ“Š TF-IDF í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ ì¤‘...")
        
        # ìƒí’ˆëª… ì „ì²˜ë¦¬
        processed_names = [self.preprocess_product_name(name) for name in df['name']]
        
        # í•œê¸€ ë‹¨ì–´ë§Œ ì¶”ì¶œí•˜ëŠ” ì»¤ìŠ¤í…€ í† í¬ë‚˜ì´ì €
        def korean_tokenizer(text):
            # í•œê¸€ 2ê¸€ì ì´ìƒ ë‹¨ì–´ë§Œ ì¶”ì¶œ
            words = re.findall(r'[ê°€-í£]{2,}', text)
            return words
        
        try:
            vectorizer = TfidfVectorizer(
                tokenizer=korean_tokenizer,
                max_features=max_features,
                min_df=2,  # ìµœì†Œ 2ë²ˆ ì´ìƒ ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ë§Œ
                lowercase=False
            )
            
            tfidf_matrix = vectorizer.fit_transform(processed_names)
            feature_names = vectorizer.get_feature_names_out()
            
            # ì „ì²´ TF-IDF ì ìˆ˜ í•©ê³„ë¡œ ì¤‘ìš”ë„ ê³„ì‚°
            scores = tfidf_matrix.sum(axis=0).A1
            keyword_scores = list(zip(feature_names, scores))
            keyword_scores.sort(key=lambda x: x[1], reverse=True)
            
            self.extracted_keywords = keyword_scores
            print(f"âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ: {len(keyword_scores)}ê°œ")
            
            return keyword_scores
            
        except Exception as e:
            print(f"âŒ TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def cluster_products_by_similarity(self, df: pd.DataFrame, n_clusters: int = 5) -> Dict[int, List[str]]:
        """ìƒí’ˆ ìœ ì‚¬ë„ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜"""
        print(f"ğŸ¯ ìƒí’ˆ í´ëŸ¬ìŠ¤í„°ë§ ({n_clusters}ê°œ í´ëŸ¬ìŠ¤í„°)...")
        
        try:
            # ìƒí’ˆëª… ì „ì²˜ë¦¬
            processed_names = [self.preprocess_product_name(name) for name in df['name']]
            
            def korean_tokenizer(text):
                return re.findall(r'[ê°€-í£]{2,}', text)
            
            vectorizer = TfidfVectorizer(
                tokenizer=korean_tokenizer,
                max_features=100,
                min_df=1,
                lowercase=False
            )
            
            tfidf_matrix = vectorizer.fit_transform(processed_names)
            
            # K-means í´ëŸ¬ìŠ¤í„°ë§
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(tfidf_matrix)
            
            # ê° í´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ í‚¤ì›Œë“œ ì¶”ì¶œ
            feature_names = vectorizer.get_feature_names_out()
            clusters = {}
            
            for i in range(n_clusters):
                cluster_center = kmeans.cluster_centers_[i]
                top_indices = cluster_center.argsort()[-5:][::-1]  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
                cluster_keywords = [feature_names[idx] for idx in top_indices]
                
                # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ìƒí’ˆë“¤
                cluster_products = df[cluster_labels == i]['name'].tolist()
                
                clusters[i] = {
                    'keywords': cluster_keywords,
                    'products': cluster_products,
                    'count': len(cluster_products)
                }
            
            self.category_clusters = clusters
            
            print(f"âœ… í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ:")
            for i, cluster_info in clusters.items():
                print(f"   í´ëŸ¬ìŠ¤í„° {i}: {cluster_info['keywords'][:3]} ({cluster_info['count']}ê°œ ìƒí’ˆ)")
            
            return clusters
            
        except Exception as e:
            print(f"âŒ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")
            return {}
    
    def calculate_sentiment_score(self, row: pd.Series) -> Dict[str, float]:
        """ë‹¤ì°¨ì› ê°ì„± ì ìˆ˜ ê³„ì‚°"""
        scores = {}
        
        # 1. í‰ì  ê¸°ë°˜ ì ìˆ˜ (0-100)
        rating = row.get('rating', 0)
        scores['rating_score'] = (rating / 5.0) * 100 if rating > 0 else 0
        
        # 2. ë¦¬ë·°ìˆ˜ ê¸°ë°˜ ì¸ê¸°ë„ ì ìˆ˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        review_count = row.get('review_count', 0)
        if review_count > 0:
            # ë¦¬ë·°ìˆ˜ë¥¼ ë¡œê·¸ ë³€í™˜í•˜ì—¬ 0-100 ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
            log_reviews = np.log1p(review_count)
            max_log_reviews = np.log1p(20000)  # ê°€ì •: ìµœëŒ€ ë¦¬ë·°ìˆ˜ 20,000
            scores['popularity_score'] = min((log_reviews / max_log_reviews) * 100, 100)
        else:
            scores['popularity_score'] = 0
        
        # 3. í• ì¸ìœ¨ ê¸°ë°˜ ê°€ì„±ë¹„ ì ìˆ˜
        discount = row.get('discount_percentage', 0)
        scores['discount_score'] = min(discount * 2, 100)  # 50% í• ì¸ì´ë©´ 100ì 
        
        # 4. ê°€ê²© ê²½ìŸë ¥ ì ìˆ˜ (ë‚®ì€ ê°€ê²©ì´ ë” ì¢‹ìŒ)
        price = row.get('price', 0)
        if price > 0:
            # ê°€ê²©ëŒ€ë³„ ìƒëŒ€ì  ì ìˆ˜ (ì¶”í›„ ì „ì²´ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì •ê·œí™”)
            scores['price_competitiveness'] = 50  # ê¸°ë³¸ê°’, ì¶”í›„ ì¡°ì •
        else:
            scores['price_competitiveness'] = 0
        
        # 5. ë² ìŠ¤íŠ¸ ìƒí’ˆ ë³´ë„ˆìŠ¤
        is_best = row.get('is_best', False)
        scores['best_bonus'] = 20 if is_best else 0
        
        # 6. ì¢…í•© ì ìˆ˜ (ê°€ì¤‘ í‰ê· )
        weights = {
            'rating_score': 0.3,
            'popularity_score': 0.25,
            'discount_score': 0.2,
            'price_competitiveness': 0.15,
            'best_bonus': 0.1
        }
        
        total_score = sum(scores[key] * weights[key] for key in weights.keys())
        scores['total_score'] = round(total_score, 1)
        
        return scores
    
    def extract_product_features(self, product_name: str) -> Dict[str, List[str]]:
        """ìƒí’ˆëª…ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        features = {
            'volume_info': [],  # ìš©ëŸ‰/ìˆ˜ëŸ‰ ì •ë³´
            'descriptive_words': [],  # ì„¤ëª… ë‹¨ì–´ë“¤
            'numbers': []  # ìˆ«ì ì •ë³´
        }
        
        # ìš©ëŸ‰/ìˆ˜ëŸ‰ ì •ë³´ ì¶”ì¶œ
        volume_patterns = [
            r'(\d+(?:\.\d+)?)(ml|L|g|kg|ê°œ|ì…)',
            r'(\d+)(íŒ©|ì„¸íŠ¸|ê°œì…)'
        ]
        
        for pattern in volume_patterns:
            matches = re.findall(pattern, product_name)
            for match in matches:
                if isinstance(match, tuple):
                    features['volume_info'].append(''.join(match))
                else:
                    features['volume_info'].append(match)
        
        # ìˆ«ì ì •ë³´ ì¶”ì¶œ
        numbers = re.findall(r'\d+', product_name)
        features['numbers'] = numbers
        
        # ì„¤ëª… ë‹¨ì–´ë“¤ (í•œê¸€ 2ê¸€ì ì´ìƒ)
        korean_words = re.findall(r'[ê°€-í£]{2,}', product_name)
        features['descriptive_words'] = korean_words
        
        return features
    
    def analyze_single_product(self, row: pd.Series, cluster_id: Optional[int] = None) -> Dict:
        """ê°œë³„ ìƒí’ˆ ë¶„ì„"""
        product_name = row['name']
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        brand = self.extract_brand_from_name(product_name)
        features = self.extract_product_features(product_name)
        sentiment_scores = self.calculate_sentiment_score(row)
        
        # í´ëŸ¬ìŠ¤í„° ì •ë³´
        cluster_info = None
        if cluster_id is not None and cluster_id in self.category_clusters:
            cluster_info = self.category_clusters[cluster_id]
        
        result = {
            'product_name': product_name,
            'brand': brand,
            'cluster_id': cluster_id,
            'cluster_keywords': cluster_info['keywords'] if cluster_info else [],
            'extracted_features': features,
            'volume_info': ', '.join(features['volume_info']),
            'descriptive_words': ', '.join(features['descriptive_words'][:10]),
            'price': row.get('price', 0),
            'original_price': row.get('original_price', 0),
            'discount_percentage': row.get('discount_percentage', 0),
            'rating': row.get('rating', 0),
            'review_count': row.get('review_count', 0),
            'is_best': row.get('is_best', False),
            **sentiment_scores
        }
        
        return result
    
    def extract_brand_from_name(self, product_name: str) -> str:
        """ìƒí’ˆëª…ì—ì„œ ë¸Œëœë“œ ì¶”ì¶œ (ë™ì )"""
        # ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª… ìš°ì„ 
        bracket_match = re.search(r'\(([^)]+)\)', product_name)
        if bracket_match:
            brand = bracket_match.group(1)
            if brand in self.extracted_brands:
                return brand
        
        # ì¶”ì¶œëœ ë¸Œëœë“œ ëª©ë¡ì—ì„œ ì°¾ê¸°
        for brand in self.extracted_brands:
            if brand in product_name:
                return brand
        
        # ì²« ë²ˆì§¸ í•œê¸€ ë‹¨ì–´ë¥¼ ë¸Œëœë“œë¡œ ê°„ì£¼
        korean_words = re.findall(r'[ê°€-í£]+', product_name)
        if korean_words:
            return korean_words[0]
        
        return 'Unknown'
    
    def run_comprehensive_analysis(self, csv_file_path: str) -> List[Dict]:
        """ì¢…í•© ë¶„ì„ ì‹¤í–‰"""
        print("\n" + "="*60)
        print("ğŸ”„ ìƒí’ˆ ì •ë³´ ì¢…í•© ë¶„ì„ ì‹œì‘")
        print("="*60)
        
        # 1. ë°ì´í„° ë¡œë“œ
        try:
            df = pd.read_csv(csv_file_path)
            print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒí’ˆ")
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
        
        # 2. í‚¤ì›Œë“œ ìë™ ì¶”ì¶œ (ë¸Œëœë“œë„ í¬í•¨)
        self.extract_keywords_tfidf(df)
        
        # 3. ìƒí’ˆ í´ëŸ¬ìŠ¤í„°ë§
        clusters = self.cluster_products_by_similarity(df)
        
        # 4. í´ëŸ¬ìŠ¤í„° ë¼ë²¨ í• ë‹¹
        if clusters:
            processed_names = [self.preprocess_product_name(name) for name in df['name']]
            
            def korean_tokenizer(text):
                return re.findall(r'[ê°€-í£]{2,}', text)
            
            vectorizer = TfidfVectorizer(
                tokenizer=korean_tokenizer,
                max_features=100,
                min_df=1,
                lowercase=False
            )
            
            tfidf_matrix = vectorizer.fit_transform(processed_names)
            kmeans = KMeans(n_clusters=len(clusters), random_state=42, n_init=10)
            cluster_labels = kmeans.fit_predict(tfidf_matrix)
            
            df['cluster_id'] = cluster_labels
        else:
            df['cluster_id'] = 0
        
        # 5. ê°€ê²© ê²½ìŸë ¥ ì ìˆ˜ ì •ê·œí™”
        if 'price' in df.columns:
            price_percentiles = df['price'].quantile([0.25, 0.75])
            df['price_competitiveness'] = df['price'].apply(
                lambda x: 75 if x <= price_percentiles[0.25] else 
                         25 if x >= price_percentiles[0.75] else 50
            )
        
        # 6. ê°œë³„ ìƒí’ˆ ë¶„ì„
        print("ğŸ” ê°œë³„ ìƒí’ˆ ë¶„ì„ ì¤‘...")
        self.analysis_results = []
        
        for idx, row in df.iterrows():
            cluster_id = row.get('cluster_id', 0)
            result = self.analyze_single_product(row, cluster_id)
            self.analysis_results.append(result)
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {len(self.analysis_results)}ê°œ ìƒí’ˆ")
        return self.analysis_results
    
    def create_comprehensive_report(self) -> str:
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± (ë‹¨ì¼ ì‹œíŠ¸)"""
        if not self.analysis_results:
            print("âŒ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"product_analysis_{timestamp}.xlsx"
        
        # ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì‹œíŠ¸ë¡œ í†µí•©
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            self._create_unified_analysis_sheet(writer)
        
        print(f"\nğŸ‰ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“„ íŒŒì¼ ê²½ë¡œ: {output_file}")
        
        return str(output_file)
    
    def _create_unified_analysis_sheet(self, writer):
        """í†µí•© ë¶„ì„ ì‹œíŠ¸ ìƒì„± (ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ì‹œíŠ¸ì—)"""
        try:
            df_results = pd.DataFrame(self.analysis_results)
            
            # í†µí•© ë¦¬í¬íŠ¸ ë°ì´í„° êµ¬ì„± - ëª¨ë“  í–‰ì´ 4ê°œ ì»¬ëŸ¼ì„ ê°€ì§€ë„ë¡ ìˆ˜ì •
            all_data = []
            
            # === 1. ë¶„ì„ ê°œìš” ===
            all_data.extend([
                ['=== ìƒí’ˆ ì •ë³´ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ===', '', '', ''],
                ['ë¶„ì„ ì¼ì‹œ', datetime.now().strftime("%Y-%m-%d %H:%M:%S"), '', ''],
                ['ì´ ìƒí’ˆ ìˆ˜', str(len(df_results)), 'ê°œ', ''],
                ['ì¶”ì¶œëœ í‚¤ì›Œë“œ ìˆ˜', str(len(self.extracted_keywords)), 'ê°œ', ''],
                ['í´ëŸ¬ìŠ¤í„° ìˆ˜', str(len(self.category_clusters)), 'ê°œ', ''],
                ['', '', '', '']
            ])
            
            # === 2. ì¢…í•© í†µê³„ ===
            all_data.extend([
                ['[ì¢…í•© í†µê³„]', '', '', ''],
                ['í‰ê·  ì¢…í•©ì ìˆ˜', f"{df_results['total_score'].mean():.1f}", 'ì ', '100ì  ë§Œì '],
                ['í‰ê·  í‰ì ', f"{df_results['rating'].mean():.2f}", 'ì ', '5ì  ë§Œì '],
                ['í‰ê·  ê°€ê²©', f"{df_results['price'].mean():,.0f}", 'ì›', ''],
                ['í‰ê·  í• ì¸ìœ¨', f"{df_results['discount_percentage'].mean():.1f}", '%', ''],
                ['ì´ ë¦¬ë·°ìˆ˜', f"{df_results['review_count'].sum():,}", 'ê°œ', ''],
                ['ë² ìŠ¤íŠ¸ ìƒí’ˆìˆ˜', str(df_results['is_best'].sum()), 'ê°œ', ''],
                ['', '', '', '']
            ])
            
            # === 3. TOP ìƒí’ˆ (ì¢…í•©ì ìˆ˜ ê¸°ì¤€) ===
            all_data.extend([
                ['[TOP 10 ìƒí’ˆ - ì¢…í•©ì ìˆ˜ ê¸°ì¤€]', '', '', ''],
                ['ìˆœìœ„', 'ìƒí’ˆëª…', 'ì¢…í•©ì ìˆ˜', 'í‰ì ']
            ])
            
            top_products = df_results.nlargest(10, 'total_score')
            for i, (idx, row) in enumerate(top_products.iterrows(), 1):
                product_name = row['product_name'][:50] + "..." if len(row['product_name']) > 50 else row['product_name']
                all_data.append([str(i), product_name, f"{row['total_score']:.1f}", f"{row['rating']:.2f}"])
            
            all_data.append(['', '', '', ''])
            
            # === 4. í‚¤ì›Œë“œ ë¶„ì„ (ë¸Œëœë“œ í¬í•¨) ===
            all_data.extend([
                ['[í‚¤ì›Œë“œ ë¶„ì„]', '', '', ''],
                ['ìˆœìœ„', 'í‚¤ì›Œë“œ', 'TF-IDFì ìˆ˜', 'ì¤‘ìš”ë„']
            ])
            
            # í‚¤ì›Œë“œ ë¶„ì„ (ë¸Œëœë“œë„ í‚¤ì›Œë“œë¡œ í¬í•¨)
            if self.extracted_keywords:
                for i, (keyword, score) in enumerate(self.extracted_keywords[:20], 1):
                    importance = "ë§¤ìš°ì¤‘ìš”" if score > np.percentile([s for _, s in self.extracted_keywords], 90) else \
                               "ì¤‘ìš”" if score > np.percentile([s for _, s in self.extracted_keywords], 70) else "ë³´í†µ"
                    all_data.append([
                        str(i),
                        keyword,
                        f"{score:.3f}",
                        importance
                    ])
            
            all_data.append(['', '', '', ''])
            
            # === 5. í´ëŸ¬ìŠ¤í„° ë¶„ì„ ===
            if self.category_clusters:
                all_data.extend([
                    ['[ìƒí’ˆ í´ëŸ¬ìŠ¤í„° ë¶„ì„]', '', '', ''],
                    ['í´ëŸ¬ìŠ¤í„°ID', 'ëŒ€í‘œí‚¤ì›Œë“œ', 'ìƒí’ˆìˆ˜', 'í‰ê· ì ìˆ˜']
                ])
                
                for cluster_id, cluster_info in self.category_clusters.items():
                    cluster_products = df_results[df_results['cluster_id'] == cluster_id]
                    if len(cluster_products) > 0:
                        keywords_str = ', '.join(cluster_info['keywords'][:3])
                        avg_score = cluster_products['total_score'].mean()
                        all_data.append([
                            f"í´ëŸ¬ìŠ¤í„° {cluster_id}",
                            keywords_str,
                            f"{len(cluster_products)}ê°œ",
                            f"{avg_score:.1f}ì "
                        ])
            
            all_data.append(['', '', '', ''])
            
            # === 6. ê°€ê²©ëŒ€ë³„ ë¶„ì„ ===
            all_data.extend([
                ['[ê°€ê²©ëŒ€ë³„ ë¶„ì„]', '', '', ''],
                ['ê°€ê²©ëŒ€', 'ìƒí’ˆìˆ˜', 'í‰ê· ì ìˆ˜', 'í‰ê· í‰ì ']
            ])
            
            # ê°€ê²©ëŒ€ êµ¬ê°„ ì„¤ì •
            price_ranges = [
                (0, 10000, '1ë§Œì› ë¯¸ë§Œ'),
                (10000, 20000, '1-2ë§Œì›'),
                (20000, 30000, '2-3ë§Œì›'),
                (30000, float('inf'), '3ë§Œì› ì´ìƒ')
            ]
            
            for min_price, max_price, range_name in price_ranges:
                range_products = df_results[
                    (df_results['price'] >= min_price) & 
                    (df_results['price'] < max_price)
                ]
                
                if len(range_products) > 0:
                    all_data.append([
                        range_name,
                        f"{len(range_products)}ê°œ",
                        f"{range_products['total_score'].mean():.1f}ì ",
                        f"{range_products['rating'].mean():.2f}ì "
                    ])
            
            all_data.append(['', '', '', ''])
            
            # === 7. í• ì¸ìœ¨ ë¶„ì„ ===
            all_data.extend([
                ['[í• ì¸ìœ¨ë³„ ë¶„ì„]', '', '', ''],
                ['í• ì¸êµ¬ê°„', 'ìƒí’ˆìˆ˜', 'í‰ê· ì ìˆ˜', 'í‰ê· í‰ì ']
            ])
            
            discount_ranges = [
                (0, 20, '20% ë¯¸ë§Œ'),
                (20, 40, '20-40%'),
                (40, 60, '40-60%'),
                (60, 100, '60% ì´ìƒ')
            ]
            
            for min_disc, max_disc, range_name in discount_ranges:
                range_products = df_results[
                    (df_results['discount_percentage'] >= min_disc) & 
                    (df_results['discount_percentage'] < max_disc)
                ]
                
                if len(range_products) > 0:
                    all_data.append([
                        range_name,
                        f"{len(range_products)}ê°œ",
                        f"{range_products['total_score'].mean():.1f}ì ",
                        f"{range_products['rating'].mean():.2f}ì "
                    ])
            
            all_data.append(['', '', '', ''])
            
            # === 8. ìƒì„¸ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ) - ì»¬ëŸ¼ ìˆ˜ ì¡°ì • ===
            all_data.extend([
                ['[ìƒì„¸ ìƒí’ˆ ì •ë³´ - TOP 20]', '', '', ''],
                ['ìˆœìœ„ | ìƒí’ˆëª…', 'ë¸Œëœë“œ | ê°€ê²©', 'í‰ì  | í• ì¸ìœ¨', 'ì¢…í•©ì ìˆ˜']
            ])
            
            top_20_products = df_results.nlargest(20, 'total_score')
            for i, (idx, row) in enumerate(top_20_products.iterrows(), 1):
                product_name = row['product_name'][:30] + "..." if len(row['product_name']) > 30 else row['product_name']
                all_data.append([
                    f"{i}. {product_name}",
                    f"{row['brand']} | {row['price']:,}ì›",
                    f"{row['rating']:.2f} | {row['discount_percentage']:.0f}%",
                    f"{row['total_score']:.1f}ì "
                ])
            
            # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ Excelì— ì €ì¥
            unified_df = pd.DataFrame(all_data, columns=['êµ¬ë¶„', 'í•­ëª©', 'ê°’', 'ì„¸ë¶€ì •ë³´'])
            unified_df.to_excel(writer, sheet_name='ì¢…í•©ë¶„ì„ë¦¬í¬íŠ¸', index=False)
            
            # ì›Œí¬ì‹œíŠ¸ ìŠ¤íƒ€ì¼ë§
            worksheet = writer.sheets['ì¢…í•©ë¶„ì„ë¦¬í¬íŠ¸']
            
            # ì»¬ëŸ¼ í­ ì¡°ì •
            worksheet.column_dimensions['A'].width = 35
            worksheet.column_dimensions['B'].width = 45
            worksheet.column_dimensions['C'].width = 25
            worksheet.column_dimensions['D'].width = 35
            
            print("âœ… í†µí•© ë¶„ì„ ì‹œíŠ¸ ìƒì„± ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ì‹œíŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°„ë‹¨í•œ ì‹œíŠ¸ë¼ë„ ìƒì„±
            simple_df = pd.DataFrame([['ì˜¤ë¥˜ ë°œìƒ', str(e), '', '']], 
                                   columns=['êµ¬ë¶„', 'í•­ëª©', 'ê°’', 'ì„¸ë¶€ì •ë³´'])
            simple_df.to_excel(writer, sheet_name='ì¢…í•©ë¶„ì„ë¦¬í¬íŠ¸', index=False)
    
    def print_analysis_summary(self):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        if not self.analysis_results:
            return
        
        df_results = pd.DataFrame(self.analysis_results)
        
        print("\n" + "="*60)
        print("ğŸ“Š ìƒí’ˆ ì •ë³´ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*60)
        
        print(f"ğŸ”¢ ì´ ìƒí’ˆ ìˆ˜: {len(df_results)}ê°œ")
        print(f"ğŸ·ï¸ ì¶”ì¶œëœ ë¸Œëœë“œ ìˆ˜: {len(self.extracted_brands)}ê°œ")
        print(f"ğŸ”¤ ì¶”ì¶œëœ í‚¤ì›Œë“œ ìˆ˜: {len(self.extracted_keywords)}ê°œ")
        print(f"ğŸ¯ í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(self.category_clusters)}ê°œ")
        
        print(f"\nğŸ“ˆ ì¢…í•© ì ìˆ˜ í†µê³„:")
        print(f"   í‰ê·  ì ìˆ˜: {df_results['total_score'].mean():.1f}")
        print(f"   ìµœê³  ì ìˆ˜: {df_results['total_score'].max():.1f}")
        print(f"   ìµœì € ì ìˆ˜: {df_results['total_score'].min():.1f}")
        
        print(f"\nğŸ† TOP 5 ìƒí’ˆ (ì¢…í•©ì ìˆ˜ ê¸°ì¤€):")
        top_products = df_results.nlargest(5, 'total_score')
        for idx, row in top_products.iterrows():
            print(f"   {row['product_name'][:50]:50} ì ìˆ˜: {row['total_score']}")
        
        print(f"\nğŸ·ï¸ ë¸Œëœë“œë³„ ìƒí’ˆ ìˆ˜:")
        brand_counts = df_results['brand'].value_counts()
        for brand, count in brand_counts.head(5).items():
            print(f"   {brand}: {count}ê°œ")
        
        print("="*60)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
    csv_file_path = "/Users/brich/Desktop/marketcrawler/crawler/operators/output/naver_brandstore_20250721_123052.csv"  # ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½
    output_dir = "/Users/brich/Desktop/marketcrawler/output"
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = ProductInfoAnalyzer(output_dir)
    
    # ì¢…í•© ë¶„ì„ ì‹¤í–‰
    results = analyzer.run_comprehensive_analysis(csv_file_path)
    
    if results:
        # ë¦¬í¬íŠ¸ ìƒì„±
        output_file = analyzer.create_comprehensive_report()
        
        # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        analyzer.print_analysis_summary()
        
        print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: {output_file}")
    else:
        print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()