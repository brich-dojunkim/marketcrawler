# main.py
"""ë©”ì¸ ì‹¤í–‰ ëª¨ë“ˆ"""

import warnings
import sys
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

warnings.filterwarnings('ignore')

from utils.data_loader import load_csv_data, identify_columns, select_columns, validate_data
from core.preprocessor import TextPreprocessor
from core.analyzer import MorphologicalAnalyzer
from core.sentiment import SentimentAnalyzer
from keywords.extractor import KeywordExtractor
from keywords.topic_modeling import TopicModeling
from visualization.charts import Visualizer
from output.excel_exporter import ExcelExporter
from config.settings import DEFAULT_DATA_FILE, DEFAULT_OUTPUT_DIR, ANALYSIS_PARAMS

class ReviewAnalysisSystem:
    """ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œ í†µí•© í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir=None):
        """
        ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.preprocessor = TextPreprocessor()
        self.analyzer = MorphologicalAnalyzer()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.keyword_extractor = KeywordExtractor()
        self.topic_modeling = TopicModeling()
        self.visualizer = Visualizer()
        self.excel_exporter = ExcelExporter(output_dir)
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.df = None
        self.text_col = None
        self.rating_col = None
        self.keywords_tfidf = None
        self.keywords_krwordrank = None
        self.topics = None
        self.sentiment_keywords = None
        self.initial_count = 0
        self.final_count = 0
    
    def load_and_prepare_data(self, file_path):
        """
        ë°ì´í„° ë¡œë”© ë° ì¤€ë¹„
        
        Args:
            file_path: CSV íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        print("ğŸš€ ì¿ íŒ¡ ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œ ì‹œì‘")
        print("=" * 50)
        
        # ë°ì´í„° ë¡œë”©
        self.df = load_csv_data(file_path)
        if self.df is None:
            return False
        
        self.initial_count = len(self.df)
        
        # ì»¬ëŸ¼ ë¶„ì„ ë° ì„ íƒ
        text_columns, rating_columns = identify_columns(self.df)
        self.text_col, self.rating_col = select_columns(text_columns, rating_columns)
        
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        if not validate_data(self.df, self.text_col, self.rating_col):
            return False
        
        print("\nğŸ”„ ë¶„ì„ ì‹œì‘...")
        print("=" * 50)
        
        return True
    
    def preprocess_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        print("1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì¤‘...")
        self.df = self.preprocessor.clean_dataframe(self.df, self.text_col)
        self.final_count = len(self.df)
    
    def tokenize_data(self, method='kiwi'):
        """í˜•íƒœì†Œ ë¶„ì„"""
        print("2. í˜•íƒœì†Œ ë¶„ì„ ì¤‘...")
        self.df = self.analyzer.tokenize_dataframe(self.df, 'cleaned_review', method)
    
    def analyze_sentiment(self):
        """ê°ì„± ë¶„ì„"""
        print("3. ê°ì„± ë¶„ì„ ì¤‘...")
        
        # ê·œì¹™ ê¸°ë°˜ ê°ì„± ë¶„ì„
        self.df = self.sentiment_analyzer.create_sentiment_labels(
            self.df, method='rule', tokens_column='tokens'
        )
        self.df = self.df.rename(columns={'sentiment': 'sentiment_rule'})
        
        # í‰ì  ê¸°ë°˜ ê°ì„± ë¶„ì„ (í‰ì  ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
        if self.rating_col:
            sentiment_rating_df = self.sentiment_analyzer.create_sentiment_labels(
                self.df, method='rating', rating_column=self.rating_col
            )
            self.df['sentiment_rating'] = sentiment_rating_df['sentiment']
    
    def extract_keywords(self):
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        print("4. í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘...")
        
        # TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ
        self.keywords_tfidf = self.keyword_extractor.extract_keywords_tfidf(
            self.df, max_features=ANALYSIS_PARAMS['max_tfidf_features'],
            ngram_range=ANALYSIS_PARAMS['ngram_range']
        )
        
        # KR-WordRank í‚¤ì›Œë“œ ì¶”ì¶œ
        try:
            self.keywords_krwordrank = self.keyword_extractor.extract_keywords_krwordrank(
                self.df, min_count=ANALYSIS_PARAMS['min_word_count']
            )
        except Exception as e:
            print(f"KR-WordRank í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            self.keywords_krwordrank = None
        
        # ê°ì„±ë³„ í‚¤ì›Œë“œ ì¶”ì¶œ
        self.sentiment_keywords = self.keyword_extractor.extract_sentiment_keywords(
            self.df, sentiment_column='sentiment_rule'
        )
    
    def perform_topic_modeling(self):
        """í† í”½ ëª¨ë¸ë§"""
        print("5. í† í”½ ëª¨ë¸ë§ ì¤‘...")
        
        try:
            self.topics = self.topic_modeling.lda_topic_modeling(
                self.df, n_topics=ANALYSIS_PARAMS['n_topics'],
                max_features=ANALYSIS_PARAMS['max_tfidf_features']
            )
        except Exception as e:
            print(f"í† í”½ ëª¨ë¸ë§ ì‹¤íŒ¨: {e}")
            self.topics = None
    
    def generate_reports(self, report_type='comprehensive'):
        """
        ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            report_type: ë¦¬í¬íŠ¸ íƒ€ì… ('comprehensive' ë˜ëŠ” 'detailed')
            
        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        print("6. ë¶„ì„ ê²°ê³¼ ì¶œë ¥ ì¤‘...")
        
        if report_type == 'comprehensive':
            output_file = self.excel_exporter.create_comprehensive_report(
                self.df, self.keywords_tfidf, self.keywords_krwordrank,
                self.topics, self.sentiment_keywords,
                self.initial_count, self.final_count,
                self.text_col, self.rating_col
            )
        elif report_type == 'detailed':
            output_file = self.excel_exporter.create_detailed_report(
                self.df, self.keywords_tfidf, self.keywords_krwordrank,
                self.topics, self.sentiment_keywords,
                self.initial_count, self.final_count,
                self.text_col, self.rating_col
            )
        else:
            raise ValueError(f"Unsupported report type: {report_type}")
        
        return output_file
    
    def print_summary(self):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 50)
        print("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 50)
        
        print(f"ì´ ë¦¬ë·° ìˆ˜: {self.initial_count:,}ê°œ â†’ {self.final_count:,}ê°œ")
        print(f"í‰ê·  ë¦¬ë·° ê¸¸ì´: {self.df['cleaned_review'].str.len().mean():.1f}ì")
        
        if self.rating_col:
            print(f"í‰ê·  í‰ì : {self.df[self.rating_col].mean():.2f}")
        
        # ê°ì„± ë¶„ì„ ê²°ê³¼
        sentiment_counts = self.df['sentiment_rule'].value_counts()
        print("\nê°ì„± ë¶„ì„ ê²°ê³¼:")
        for sentiment, count in sentiment_counts.items():
            ratio = count / len(self.df) * 100
            sentiment_kr = {'positive': 'ê¸ì •', 'negative': 'ë¶€ì •', 'neutral': 'ì¤‘ë¦½'}[sentiment]
            print(f"  {sentiment_kr}: {count:,}ê°œ ({ratio:.1f}%)")
        
        # ì£¼ìš” í‚¤ì›Œë“œ
        print("\nì£¼ìš” í‚¤ì›Œë“œ (TF-IDF TOP 10):")
        for i, (word, score) in enumerate(self.keywords_tfidf[:10], 1):
            print(f"  {i:2d}. {word} ({score:.3f})")
        
        print("=" * 50)
    
    def create_visualizations(self):
        """ì‹œê°í™” ìƒì„±"""
        print("7. ì‹œê°í™” ìƒì„± ì¤‘...")
        
        # ê°ì„± ë¶„í¬
        self.visualizer.plot_sentiment_distribution(self.df, 'sentiment_rule', self.rating_col)
        
        # ì›Œë“œí´ë¼ìš°ë“œ
        self.visualizer.create_wordcloud(self.df)
        
        # í‚¤ì›Œë“œ ë­í‚¹
        if self.keywords_tfidf:
            self.visualizer.plot_keyword_ranking(self.keywords_tfidf, 'TF-IDF í‚¤ì›Œë“œ ë­í‚¹')
        
        # í‰ì ë³„ ê°ì„± ë¶„í¬ (í‰ì ì´ ìˆëŠ” ê²½ìš°)
        if self.rating_col:
            self.visualizer.plot_sentiment_by_rating(self.df, self.rating_col, 'sentiment_rule')
        
        # í† í”½ ë¶„í¬ (í† í”½ì´ ìˆëŠ” ê²½ìš°)
        if self.topics:
            self.visualizer.plot_topic_distribution(self.topics)
    
    def run_full_analysis(self, file_path, report_type='comprehensive', create_viz=False):
        """
        ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            file_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
            report_type: ë¦¬í¬íŠ¸ íƒ€ì… ('comprehensive' ë˜ëŠ” 'detailed')
            create_viz: ì‹œê°í™” ìƒì„± ì—¬ë¶€
            
        Returns:
            ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            if not self.load_and_prepare_data(file_path):
                return None
            
            # 2. ì „ì²˜ë¦¬
            self.preprocess_data()
            
            # 3. í˜•íƒœì†Œ ë¶„ì„
            self.tokenize_data()
            
            # 4. ê°ì„± ë¶„ì„
            self.analyze_sentiment()
            
            # 5. í‚¤ì›Œë“œ ì¶”ì¶œ
            self.extract_keywords()
            
            # 6. í† í”½ ëª¨ë¸ë§
            self.perform_topic_modeling()
            
            # 7. ë¦¬í¬íŠ¸ ìƒì„±
            output_file = self.generate_reports(report_type)
            
            # 8. ì‹œê°í™” (ì„ íƒì‚¬í•­)
            if create_viz:
                self.create_visualizations()
            
            # 9. ìš”ì•½ ì¶œë ¥
            self.print_summary()
            
            print(f"\nğŸ‰ ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_file}")
            
            return output_file
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    file_path = f'{DEFAULT_OUTPUT_DIR}/{DEFAULT_DATA_FILE}'
    output_dir = DEFAULT_OUTPUT_DIR
    
    # ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = ReviewAnalysisSystem(output_dir)
    
    # ì „ì²´ ë¶„ì„ ì‹¤í–‰
    output_file = system.run_full_analysis(
        file_path=file_path,
        report_type='comprehensive',  # 'comprehensive' ë˜ëŠ” 'detailed'
        create_viz=False  # ì‹œê°í™” ìƒì„± ì—¬ë¶€
    )
    
    return output_file

def run_with_custom_file(file_path, output_dir=None, report_type='comprehensive'):
    """
    ì‚¬ìš©ì ì •ì˜ íŒŒì¼ë¡œ ë¶„ì„ ì‹¤í–‰
    
    Args:
        file_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì¸ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©)
        report_type: ë¦¬í¬íŠ¸ íƒ€ì… ('comprehensive' ë˜ëŠ” 'detailed')
        
    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    system = ReviewAnalysisSystem(output_dir)
    return system.run_full_analysis(file_path, report_type)

def analyze_with_visualization(file_path, output_dir=None):
    """
    ì‹œê°í™” í¬í•¨ ë¶„ì„ ì‹¤í–‰
    
    Args:
        file_path: ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    system = ReviewAnalysisSystem(output_dir)
    return system.run_full_analysis(
        file_path=file_path,
        report_type='comprehensive',
        create_viz=True
    )

if __name__ == "__main__":
    main()