# main.py
"""ë©”ì¸ ì‹¤í–‰ ëª¨ë“ˆ - ë°ì´í„° ê¸°ë°˜ ë¶„ì„"""

import warnings
import sys
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

warnings.filterwarnings('ignore')

from utils.data_loader import load_csv_data, identify_columns, validate_data
from core.analyzer import MorphologicalAnalyzer
from core.sentiment import SentimentAnalyzer
from keywords.extractor import KeywordExtractor
from output.excel_exporter import ExcelExporter
from config.settings import DEFAULT_DATA_FILE, DEFAULT_OUTPUT_DIR, ANALYSIS_PARAMS

class DataDrivenReviewAnalysisSystem:
    """ë°ì´í„° ê¸°ë°˜ ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œ"""
    
    def __init__(self, output_dir=None):
        """
        ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.analyzer = MorphologicalAnalyzer()
        self.sentiment_analyzer = SentimentAnalyzer()
        self.keyword_extractor = KeywordExtractor()
        self.excel_exporter = ExcelExporter(output_dir)
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.df = None
        self.text_col = None
        self.rating_col = None
        self.meaningful_phrases = None
        self.cluster_topics = None
        self.sentiment_keywords = None
        self.learned_patterns = None
        self.transformers_comparison = None
        self.initial_count = 0
        self.final_count = 0
    
    def load_and_prepare_data(self, file_path):
        """ë°ì´í„° ë¡œë”© ë° ì¤€ë¹„"""
        print("ğŸš€ ë°ì´í„° ê¸°ë°˜ ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œ")
        print("=" * 50)
        
        # ë°ì´í„° ë¡œë”©
        self.df = load_csv_data(file_path)
        if self.df is None:
            return False
        
        self.initial_count = len(self.df)
        
        # ì»¬ëŸ¼ ë¶„ì„ ë° ì„ íƒ
        text_columns, rating_columns = identify_columns(self.df)
        
        # body ì»¬ëŸ¼ ìš°ì„  ì„ íƒ (ë” í’ë¶€í•œ ë‚´ìš©)
        if 'body' in text_columns:
            self.text_col = 'body'
            print("ğŸ“ í…ìŠ¤íŠ¸ ì»¬ëŸ¼: 'body' (ìƒì„¸ ë‚´ìš© ìš°ì„  ì„ íƒ)")
        elif text_columns:
            self.text_col = text_columns[0]
            print(f"ğŸ“ í…ìŠ¤íŠ¸ ì»¬ëŸ¼: '{self.text_col}'")
        else:
            print("âŒ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        self.rating_col = rating_columns[0] if rating_columns else None
        if self.rating_col:
            print(f"â­ í‰ì  ì»¬ëŸ¼: '{self.rating_col}'")
        else:
            print("âš ï¸ í‰ì  ì»¬ëŸ¼ ì—†ìŒ (í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„ë§Œ ìˆ˜í–‰)")
        
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        if not validate_data(self.df, self.text_col, self.rating_col):
            return False
        
        self.final_count = len(self.df)
        
        print("\nğŸ”„ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì‹œì‘...")
        print("=" * 50)
        
        return True
    
    def preprocess_data(self):
        """ì „ì²˜ë¦¬ ìƒëµ - ì›ë³¸ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©"""
        print("1. ì›ë³¸ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì „ì²˜ë¦¬ ìƒëµ)")
        
        # ë‹¨ìˆœíˆ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬
        self.df['cleaned_review'] = self.df[self.text_col]
        self.final_count = len(self.df)
        
        print(f"âœ… ì›ë³¸ í…ìŠ¤íŠ¸ ìœ ì§€: {self.final_count:,}ê°œ ë¦¬ë·°")
        print(f"ğŸ“ í‰ê·  í…ìŠ¤íŠ¸ ê¸¸ì´: {self.df['cleaned_review'].str.len().mean():.1f}ì")
    
    def tokenize_data(self, method='kiwi'):
        """í˜•íƒœì†Œ ë¶„ì„ - ì›ë³¸ í…ìŠ¤íŠ¸ ì§ì ‘ ì‚¬ìš©"""
        print("2. í˜•íƒœì†Œ ë¶„ì„ ì¤‘... (ì›ë³¸ í…ìŠ¤íŠ¸ ì§ì ‘ ì‚¬ìš©)")
        self.df = self.analyzer.tokenize_dataframe(self.df, self.text_col, method)
    
    def extract_auto_stopwords(self):
        """ìë™ ë¶ˆìš©ì–´ ì¶”ì¶œ"""
        print("3. ìë™ ë¶ˆìš©ì–´ ì¶”ì¶œ ì¤‘...")
        texts = self.df['tokens_str'].tolist()
        self.keyword_extractor.extract_auto_stopwords(
            texts, ANALYSIS_PARAMS['auto_stopword_threshold']
        )
    
    def analyze_sentiment(self):
        """ë°ì´í„° ê¸°ë°˜ ê°ì„± ë¶„ì„ (Transformers í¬í•¨)"""
        print("4. ê³ ê¸‰ ê°ì„± ë¶„ì„ ì¤‘...")
        
        if self.rating_col:
            # ì•™ìƒë¸” ë°©ì‹: í‰ì  + Transformers + í•™ìŠµëœ íŒ¨í„´
            self.df = self.sentiment_analyzer.create_sentiment_labels(
                self.df, 
                method='ensemble',  # ğŸ†• ì•™ìƒë¸” ë°©ì‹
                tokens_column='tokens',
                rating_column=self.rating_col,
                text_column=self.text_col  # ì›ë³¸ í…ìŠ¤íŠ¸ (Transformersìš©)
            )
            
            # í•™ìŠµëœ íŒ¨í„´ë„ ì €ì¥
            self.learned_patterns = self.sentiment_analyzer.get_learned_patterns()
            
            # Transformers vs í‰ì  ê¸°ë°˜ ë¹„êµ ë¶„ì„
            if hasattr(self.sentiment_analyzer, 'transformers_pipeline') and self.sentiment_analyzer.transformers_pipeline:
                comparison = self.sentiment_analyzer.compare_sentiment_methods(self.df)
                self.transformers_comparison = comparison
            
        else:
            # í‰ì ì´ ì—†ëŠ” ê²½ìš° Transformersë§Œ ì‚¬ìš©
            self.df = self.sentiment_analyzer.create_sentiment_labels(
                self.df,
                method='transformers',
                text_column=self.text_col
            )
            print("âš ï¸ í‰ì ì´ ì—†ì–´ Transformers ê¸°ë°˜ ê°ì„± ë¶„ì„ë§Œ ìˆ˜í–‰")
    
    def extract_meaningful_content(self):
        """ì˜ë¯¸ìˆëŠ” ì½˜í…ì¸  ì¶”ì¶œ"""
        print("5. ì˜ë¯¸ìˆëŠ” ì½˜í…ì¸  ì¶”ì¶œ ì¤‘...")
        
        texts = self.df['tokens_str'].tolist()
        
        # ì˜ë¯¸ìˆëŠ” êµ¬ë¬¸ ì¶”ì¶œ (N-gram ê¸°ë°˜)
        self.meaningful_phrases = self.keyword_extractor.extract_meaningful_phrases(
            texts, 
            min_freq=ANALYSIS_PARAMS['min_phrase_freq'],
            max_ngram=ANALYSIS_PARAMS['ngram_range'][1]
        )
        
        # í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ í† í”½ ì¶”ì¶œ
        self.cluster_topics, self.df = self.keyword_extractor.cluster_based_topics(
            self.df, 'tokens_str', ANALYSIS_PARAMS['n_topics']
        )
        
        # ê°ì„±ë³„ íŠ¹ì§• í‚¤ì›Œë“œ
        self.sentiment_keywords = self.keyword_extractor.extract_sentiment_keywords(
            self.df, 'sentiment', 'tokens_str'
        )
    
    def generate_data_driven_report(self):
        """ë°ì´í„° ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("6. ë°ì´í„° ê¸°ë°˜ ê²°ê³¼ ì¶œë ¥ ì¤‘...")
        
        # ì—‘ì…€ ë¦¬í¬íŠ¸ ìƒì„±
        output_file = self.create_comprehensive_excel_report()
        
        return output_file
    
    def print_analysis_summary(self):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 50)
        print("ğŸ“Š ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 50)
        
        # ê¸°ë³¸ í†µê³„
        print(f"ğŸ“ˆ ë°ì´í„° í˜„í™©:")
        print(f"   ì´ ë¦¬ë·° ìˆ˜: {self.initial_count:,}ê°œ â†’ {self.final_count:,}ê°œ")
        print(f"   í‰ê·  ë¦¬ë·° ê¸¸ì´: {self.df[self.text_col].str.len().mean():.1f}ì")
        print(f"   í…ìŠ¤íŠ¸ ì»¬ëŸ¼: {self.text_col}")
        
        if self.rating_col:
            print(f"   í‰ê·  í‰ì : {self.df[self.rating_col].mean():.2f}")
        
        # ìë™ ì¶”ì¶œ ê²°ê³¼
        print(f"\nğŸ¤– ìë™ ì¶”ì¶œ ê²°ê³¼:")
        print(f"   ìë™ ë¶ˆìš©ì–´: {len(self.keyword_extractor.auto_stopwords)}ê°œ")
        if self.learned_patterns:
            print(f"   í•™ìŠµëœ ê°ì„± íŒ¨í„´: ê¸ì • {len(self.learned_patterns.get('positive', []))}ê°œ, "
                  f"ë¶€ì • {len(self.learned_patterns.get('negative', []))}ê°œ")
        print(f"   ì˜ë¯¸êµ¬ë¬¸: {len(self.meaningful_phrases)}ê°œ")
        print(f"   í† í”½ í´ëŸ¬ìŠ¤í„°: {len(self.cluster_topics)}ê°œ")
        
        # ê°ì„± ë¶„í¬
        if 'sentiment' in self.df.columns:
            sentiment_counts = self.df['sentiment'].value_counts()
            print(f"\nğŸ’­ ê°ì„± ë¶„í¬ (í‰ì  ê¸°ë°˜):")
            for sentiment, count in sentiment_counts.items():
                ratio = count / len(self.df) * 100
                sentiment_kr = {'positive': 'ê¸ì •', 'negative': 'ë¶€ì •', 'neutral': 'ì¤‘ë¦½'}[sentiment]
                print(f"   {sentiment_kr}: {count:,}ê°œ ({ratio:.1f}%)")
        
        # ì£¼ìš” ì˜ë¯¸êµ¬ë¬¸
        print(f"\nğŸ¯ ì£¼ìš” ì˜ë¯¸êµ¬ë¬¸ TOP 10:")
        for i, (phrase, score) in enumerate(self.meaningful_phrases[:10], 1):
            print(f"   {i:2d}. {phrase} ({score:.1f})")
        
        # í† í”½ í´ëŸ¬ìŠ¤í„°
        print(f"\nğŸ“‹ í† í”½ í´ëŸ¬ìŠ¤í„°:")
        for topic_name, topic_info in self.cluster_topics.items():
            keywords = ', '.join(topic_info['keywords'][:5])
            print(f"   {topic_name} ({topic_info['ratio']:.1%}): {keywords}")
        
        print("=" * 50)
    
    def create_comprehensive_excel_report(self):
        """ì¢…í•© ì—‘ì…€ ë¦¬í¬íŠ¸ ìƒì„±"""
        from datetime import datetime
        import pandas as pd
        
        output_file = os.path.join(
            self.excel_exporter.output_dir, 
            f"data_driven_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        )
        
        # ë¦¬í¬íŠ¸ ë°ì´í„° êµ¬ì„±
        report_data = []
        
        # ë¶„ì„ ê°œìš”
        report_data.extend([
            ['=== ë°ì´í„° ê¸°ë°˜ ë¦¬ë·° ë¶„ì„ ë¦¬í¬íŠ¸ ===', '', ''],
            ['ë¶„ì„ ë°©ì‹', 'ë°ì´í„° ê¸°ë°˜ (í•˜ë“œì½”ë”© ìµœì†Œí™”)', 'í‰ì  ê¸°ë°˜ ê°ì„±ë¶„ì„, ìë™ ë¶ˆìš©ì–´, ì˜ë¯¸êµ¬ë¬¸ ì¶”ì¶œ'],
            ['ë¶„ì„ ì¼ì‹œ', datetime.now().strftime("%Y-%m-%d %H:%M:%S"), ''],
            ['', '', '']
        ])
        
        # ê¸°ë³¸ í†µê³„
        report_data.extend([
            ['[ê¸°ë³¸ í†µê³„]', '', ''],
            ['ì´ ë¦¬ë·° ìˆ˜ (ì›ë³¸)', f"{self.initial_count:,}ê°œ", ''],
            ['ë¶„ì„ëœ ë¦¬ë·° ìˆ˜', f"{self.final_count:,}ê°œ", ''],
            ['í…ìŠ¤íŠ¸ ì»¬ëŸ¼', self.text_col, ''],
            ['í‰ì  ì»¬ëŸ¼', self.rating_col or 'ì—†ìŒ', ''],
            ['í‰ê·  ë¦¬ë·° ê¸¸ì´', f"{self.df[self.text_col].str.len().mean():.1f}ì", '']
        ])
        
        if self.rating_col and self.rating_col in self.df.columns:
            report_data.append(['í‰ê·  í‰ì ', f"{self.df[self.rating_col].mean():.2f}", ''])
        
        report_data.append(['', '', ''])
        
        # ìë™ ì¶”ì¶œ í˜„í™©
        report_data.extend([
            ['[ìë™ ì¶”ì¶œ í˜„í™©]', '', ''],
            ['ìë™ ë¶ˆìš©ì–´ ìˆ˜', f"{len(self.keyword_extractor.auto_stopwords)}ê°œ", 'ë¬¸ì„œ ë¹ˆë„ 50% ì´ìƒ'],
            ['ì˜ë¯¸êµ¬ë¬¸ ìˆ˜', f"{len(self.meaningful_phrases)}ê°œ", 'N-gram ê¸°ë°˜ ìë™ ì¶”ì¶œ'],
            ['í† í”½ í´ëŸ¬ìŠ¤í„° ìˆ˜', f"{len(self.cluster_topics)}ê°œ", 'K-means í´ëŸ¬ìŠ¤í„°ë§'],
        ])
        
        if self.learned_patterns:
            pos_count = len(self.learned_patterns.get('positive', []))
            neg_count = len(self.learned_patterns.get('negative', []))
            report_data.append(['í•™ìŠµëœ ê°ì„± íŒ¨í„´', f"ê¸ì • {pos_count}ê°œ, ë¶€ì • {neg_count}ê°œ", 'í‰ì  4+ vs 2- ê¸°ë°˜ í•™ìŠµ'])
        
        report_data.append(['', '', ''])
        
        # ê°ì„± ë¶„ì„ ê²°ê³¼
        if 'sentiment' in self.df.columns:
            sentiment_counts = self.df['sentiment'].value_counts()
            report_data.extend([
                ['[ê°ì„± ë¶„ì„ ê²°ê³¼]', '', ''],
                ['ê¸ì • ë¦¬ë·°', f"{sentiment_counts.get('positive', 0):,}ê°œ ({sentiment_counts.get('positive', 0)/len(self.df)*100:.1f}%)", 'í‰ì  ê¸°ë°˜'],
                ['ë¶€ì • ë¦¬ë·°', f"{sentiment_counts.get('negative', 0):,}ê°œ ({sentiment_counts.get('negative', 0)/len(self.df)*100:.1f}%)", 'í‰ì  ê¸°ë°˜'],
                ['ì¤‘ë¦½ ë¦¬ë·°', f"{sentiment_counts.get('neutral', 0):,}ê°œ ({sentiment_counts.get('neutral', 0)/len(self.df)*100:.1f}%)", 'í‰ì  ê¸°ë°˜'],
                ['', '', '']
            ])
        
        # ì£¼ìš” ì˜ë¯¸êµ¬ë¬¸
        report_data.extend([
            ['[ì£¼ìš” ì˜ë¯¸êµ¬ë¬¸ TOP 20]', '', ''],
            ['ìˆœìœ„', 'ì˜ë¯¸êµ¬ë¬¸', 'ì ìˆ˜']
        ])
        
        for i, (phrase, score) in enumerate(self.meaningful_phrases[:20], 1):
            report_data.append([i, phrase, round(score, 2)])
        
        report_data.append(['', '', ''])
        
        # í† í”½ í´ëŸ¬ìŠ¤í„°
        report_data.extend([
            ['[í† í”½ í´ëŸ¬ìŠ¤í„° ë¶„ì„]', '', ''],
            ['í† í”½', 'ì£¼ìš” í‚¤ì›Œë“œ', 'ë¬¸ì„œ ìˆ˜ (ë¹„ìœ¨)']
        ])
        
        for topic_name, topic_info in self.cluster_topics.items():
            keywords = ', '.join(topic_info['keywords'][:8])
            size_info = f"{topic_info['size']}ê°œ ({topic_info['ratio']:.1%})"
            report_data.append([topic_name, keywords, size_info])
        
        report_data.append(['', '', ''])
        
        # ê°ì„±ë³„ íŠ¹ì§• í‚¤ì›Œë“œ
        if self.sentiment_keywords:
            report_data.extend([
                ['[ê°ì„±ë³„ íŠ¹ì§• í‚¤ì›Œë“œ]', '', ''],
                ['ê°ì„±', 'íŠ¹ì§• í‚¤ì›Œë“œ', 'ì„¤ëª…']
            ])
            
            for sentiment in ['positive', 'negative', 'neutral']:
                if sentiment in self.sentiment_keywords and self.sentiment_keywords[sentiment]:
                    keywords = ', '.join([word for word, score in self.sentiment_keywords[sentiment][:10]])
                    sentiment_kr = {'positive': 'ê¸ì •', 'negative': 'ë¶€ì •', 'neutral': 'ì¤‘ë¦½'}[sentiment]
                    report_data.append([sentiment_kr, keywords, f'{sentiment_kr} ë¦¬ë·°ì˜ íŠ¹ì§•ì  í‘œí˜„'])
        
        # Excel íŒŒì¼ ìƒì„±
        df_report = pd.DataFrame(report_data, columns=['í•­ëª©', 'ê°’', 'ì„¤ëª…'])
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            df_report.to_excel(writer, sheet_name='ë°ì´í„°ê¸°ë°˜_ë¶„ì„_ë¦¬í¬íŠ¸', index=False)
            self.excel_exporter._style_worksheet(writer.sheets['ë°ì´í„°ê¸°ë°˜_ë¶„ì„_ë¦¬í¬íŠ¸'], report_data)
        
        print(f"âœ… ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥:")
        print(f"ğŸ“ íŒŒì¼ ê²½ë¡œ: {output_file}")
        
        return output_file
    
    def run_full_analysis(self, file_path):
        """ì „ì²´ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        try:
            # 1. ë°ì´í„° ì¤€ë¹„
            if not self.load_and_prepare_data(file_path):
                return None
            
            # 2. í˜•íƒœì†Œ ë¶„ì„ (ì „ì²˜ë¦¬ ì—†ì´ ë°”ë¡œ)
            self.tokenize_data()
            
            # 3. ìë™ ë¶ˆìš©ì–´ ì¶”ì¶œ
            self.extract_auto_stopwords()
            
            # 4. ê°ì„± ë¶„ì„
            self.analyze_sentiment()
            
            # 5. ì˜ë¯¸ìˆëŠ” ì½˜í…ì¸  ì¶”ì¶œ
            self.extract_meaningful_content()
            
            # 6. ë¦¬í¬íŠ¸ ìƒì„±
            output_file = self.generate_data_driven_report()
            
            # 7. ìš”ì•½ ì¶œë ¥
            self.print_analysis_summary()
            
            print(f"\nğŸ‰ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ!")
            print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {output_file}")
            
            return output_file
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - í„°ë¯¸ë„ ì…ë ¥ ë°©ì‹"""
    
    # ì‚¬ìš©ìë¡œë¶€í„° ê²½ë¡œ ì…ë ¥ë°›ê¸°
    from config.settings import get_user_paths
    
    input_file, output_dir = get_user_paths()
    
    if not input_file:
        print("âŒ ì˜¬ë°”ë¥¸ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return None
    
    print(f"\nğŸš€ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“ ì…ë ¥: {input_file}")
    print(f"ğŸ“ ì¶œë ¥: {output_dir}")
    
    # ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = DataDrivenReviewAnalysisSystem(output_dir)
    
    # ì „ì²´ ë¶„ì„ ì‹¤í–‰
    output_file = system.run_full_analysis(input_file)
    
    return output_file

if __name__ == "__main__":
    main()